<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Consciousness as Integrated Information: a Provisional Manifesto </title>
      <meta name="googlebot" content="NOODP">
      <meta name="HW.ad-path" content="/cgi/content/full/215/3/216">
      <meta content="/biolbull/215/3/216.atom" name="HW.identifier">
      <meta name="DC.Format" content="text/html">
      <meta name="DC.Language" content="en">
      <meta content="Consciousness as Integrated Information: a Provisional Manifesto" name="DC.Title">
      <meta content="" name="DC.Identifier">
      <meta content="2008-12-01" name="DC.Date">
      <meta content="Marine Biological Laboratory" name="DC.Publisher">
      <meta content="Giulio Tononi" name="DC.Contributor">
      <meta content="The Biological Bulletin" name="citation_journal_title">
      <meta content="Biol
                Bull" name="citation_journal_abbrev">
      <meta content="0006-3185" name="citation_issn">
      <meta content="1939-8697" name="citation_issn">
      <meta name="citation_author" content="Giulio Tononi">
      <meta content="Consciousness as Integrated Information: a Provisional Manifesto" name="citation_title">
      <meta content="12/01/2008" name="citation_date">
      <meta content="215" name="citation_volume">
      <meta content="3" name="citation_issue">
      <meta content="216" name="citation_firstpage">
      <meta content="242" name="citation_lastpage">
      <meta content="215/3/216" name="citation_id">
      <meta content="215/3/216" name="citation_id_from_sass_path">
      <meta content="biolbull;215/3/216" name="citation_mjid">
      <meta content="http://www.biolbull.org/content/215/3/216.abstract" name="citation_abstract_html_url">
      <meta content="http://www.biolbull.org/content/215/3/216.full" name="citation_fulltext_html_url">
      <meta content="http://www.biolbull.org/content/215/3/216.full.pdf" name="citation_pdf_url">
      <meta content="http://www.biolbull.org/content/215/3/216" name="citation_public_url">
      <meta content="19098144" name="citation_pmid">
      <meta name="citation_section" content="Position Papers">
      <meta name="robots" content="noarchive,nofollow">
      <meta name="googlebot" content="noarchive">
      <link href="http://www.biolbull.org/content/215/3/204.short" rel="prev">
      <link href="http://www.biolbull.org/content/215/3/243.short" rel="next">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-global.css">
      <link rel="stylesheet" type="text/css" media="print" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-print.css">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/main.css">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-local-global.css">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-page-content.css">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/jquery.css">
      <link rel="stylesheet" type="text/css" media="all" href="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-global-colexpand.css"><script type="text/javascript" id="session-d6742438e1">var callbackToken='5699300FC5C930E';</script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/jquery-min.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-shared.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-design1.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-content.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/AccessCheckLib.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/executeAccessCheck.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/jquery.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/jquery_002.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/jquery_003.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/content.js"></script><script type="text/javascript" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hw-col-expand.js"></script></head>
   <body>
      <div class="hw-gen-page pagetype-content" id="pageid-content" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle">
         <div id="header">
            
            <h1><a id="logo" href="http://www.biolbull.org/"><span>The Biological Bulletin</span></a></h1>
            
            <p id="skip-link">
               <a href="#content-block">Skip to main page content</a>
               
            </p>
            
            <ul class="button-list header-buttons">
               <li class="first"><a href="http://www.biolbull.org/" title="HOME"><span>HOME</span></a></li>
               <li><a href="http://www.biolbull.org/content/current/" title="CURRENT ISSUE"><span>CURRENT ISSUE</span></a></li>
               <li><a href="http://www.biolbull.org/site/subscriptions" title="SUBSCRIBE"><span>SUBSCRIBE</span></a></li>
               <li><a href="http://www.biolbull.org/archive" title="ARCHIVE"><span>ARCHIVE</span></a></li>
               <li><a href="http://www.biolbull.org/site/misc/contact.xhtml" title="CONTACT US"><span>CONTACT US</span></a></li>
               <li><a href="http://www.biolbull.org/feedback" title="FEEDBACK"><span>FEEDBACK</span></a></li>
               <li class="last"><a href="http://www.biolbull.org/site/misc/permissions.xhtml" title="PERMISSIONS"><span>PERMISSIONS</span></a></li>
            </ul>
            
            
            <div class="header-qs">
               
               <form class="searchbox" action="/search" method="get">
                  <div>
                     	<label for="header-qs-input" id="header-qs-search-label">Search for Keyword:</label>
                     <input style="color: rgb(160, 160, 160);" value="Search for Keyword:" title="Search" name="fulltext" id="header-qs-input" type="text"><input name="submit" value="yes" type="hidden"><a href="#" id="hdr-qs-search-a"><label for="header-qs-search" id="header-qs-search-label">GO</label></a><input value="GO" alt="Link: Go" id="header-qs-search-go" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/go.gif" type="image"> 
                     
                  </div>
                  <div class="adv-search-link"><a href="http://www.biolbull.org/search">Advanced Search</a></div>
               </form>
               
               
            </div>
            
            <div class="header-ac-elements">
               
               <div id="authstring">
                  
                  
               </div> 
               
               <div id="hdr-login">
                  
                  <form action="/login" method="post">
                     <div>
                        <label for="hdr-login-username" id="hdr-login-username-label">User Name</label>
                        <input value="User Name" style="color: rgb(160, 160, 160);" name="username" id="hdr-login-username" type="text">
                        <label for="hdr-login-password" id="hdr-login-password-label">Password</label>
                        <input style="color: rgb(160, 160, 160);" name="code" id="hdr-login-password" type="password">
                        <a href="#" id="hdr-login-signin-label-a"><label for="hdr-login-signin" id="hdr-login-signin-label">
                           Sign In
                           </label></a>
                        <input style="color: rgb(160, 160, 160);" value="http://www.biolbull.org/content/215/3/216.full" name="uri" type="hidden">
                        <input style="color: rgb(160, 160, 160);" alt="sign in" value="
                           Sign In
                           " id="hdr-login-signin" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/login.gif" type="image">
                        
                     </div>
                  </form>
                  
               </div>
               
            </div>
            
            <div class="banner-ads">
               
               <ul>
                  <li class="position-1 hdr_left"><a href="http://www.biolbull.org/cgi/adclick/?ad=40239&amp;adclick=true&amp;url=http%3A%2F%2Fwww.mbl.edu%2F"><img title="Advertisement" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/mbl%2520banner.jpg" alt="Advertisement"></a></li>
               </ul>
               
            </div>
            
            <div class="bar">
               
               <div class="bar-inner"></div>
               
            </div>
            
         </div>
         <div style="height: 37233px;" id="content-block"><div class="option-box-docked" style="display: block; left: 750.117px;" id="content-option-box" title="Expand this column"><ul><li id="content-toggle"><a href="#"><span class="descr">Expand</span><span>+</span></a></li></ul></div><div id="print-slug" class="print-only"><span class="jnl-title">The Biological Bulletin</span><span class="jnl-url">www.biolbull.org</span><div class="cb-section cb-slug">
                     <ol>
                        <li>
                           <div id="slugline">
                              
                              
                              	    
                              
                              <cite>
                                 	    <abbr title="The Biological Bulletin" class="slug-jnl-abbrev">
                                    Biol. Bull.</abbr><span class="slug-pub-date" itemprop="datePublished">
                                    	    December 2008 
                                    </span>
                                 	    <span class="slug-vol">
                                    vol. 215 
                                    </span><span class="slug-issue">
                                    no. 3 
                                    </span><span class="slug-pages">
                                    216-242
                                    </span>
                                 </cite>
                              
                              
                              
                           </div>
                        </li>
                     </ol>
                  </div></div>
            <div class="article fulltext-view" itemprop="articleBody"><span class="highwire-journal-article-marker-start"></span><h1 id="article-title-1" itemprop="headline">Consciousness as Integrated Information: a Provisional Manifesto </h1>
               <div class="contributors">
                  <ol class="contributor-list" id="contrib-group-1">
                     <li class="last" id="contrib-1"><span class="name"><a class="name-search" href="http://www.biolbull.org/search?author1=Giulio+Tononi&amp;sortspec=date&amp;submit=Submit">Giulio Tononi</a></span><a id="xref-aff-1-1" class="xref-aff" href="#aff-1"></a><a id="xref-corresp-1-1" class="xref-down-link" href="#corresp-1"><span>⇓</span></a></li>
                  </ol><p class="affiliation-list-reveal"><a href="#" class="view-more">+</a> Author Affiliations</p>
                  <ol class="affiliation-list hideaffil">
                     <li class="aff"><a id="aff-1" name="aff-1"></a><address>Department of Psychiatry, University of Wisconsin, Madison, Wisconsin</address>
                     </li>
                  </ol>
                  <ol class="corresp-list">
                     <li class="corresp" id="corresp-1"><span class="corresp-label">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:gtononi@wisc.edu">gtononi@wisc.edu</a></li>
                  </ol>
               </div>
               <div class="section abstract" id="abstract-1" itemprop="description">
                  <div class="section-nav">
                     <div class="nav-placeholder">&nbsp;</div><a href="#sec-1" title="INTRODUCTION" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>Abstract</h2>
                  <p id="p-1">The integrated information theory (IIT) 
starts from phenomenology and makes use of thought experiments to claim 
that consciousness
                     is integrated information. Specifically: (i) the 
quantity of consciousness corresponds to the amount of integrated 
information
                     generated by a complex of elements; (ii) the 
quality of experience is specified by the set of informational 
relationships
                     generated within that complex. Integrated 
information (Φ) is defined as the amount of information generated by a 
complex of
                     elements, above and beyond the information 
generated by its parts. Qualia space (Q) is a space where each axis 
represents
                     a possible state of the complex, each point is a 
probability distribution of its states, and arrows between points 
represent
                     the informational relationships among its elements 
generated by causal mechanisms (connections). Together, the set of 
informational
                     relationships within a complex constitute a shape 
in Q that completely and univocally specifies a particular experience. 
Several
                     observations concerning the neural substrate of 
consciousness fall naturally into place within the IIT framework. Among 
them
                     are the association of consciousness with certain 
neural systems rather than with others; the fact that neural processes 
underlying
                     consciousness can influence or be influenced by 
neural processes that remain unconscious; the reduction of consciousness
 during
                     dreamless sleep and generalized seizures; and the 
distinct role of different cortical architectures in affecting the 
quality
                     of experience. Equating consciousness with 
integrated information carries several implications for our view of 
nature.
                  </p>
               </div>
               <ul class="kwd-group ABR">
                  <li class="kwd"><span><a class="kwd-search" href="http://www.biolbull.org/search?fulltext=%CE%A6,+integrated+information&amp;sortspec=date&amp;submit=Submit&amp;andorexactfulltext=phrase">Φ, integrated information</a></span></li>
                  <li class="kwd"><span><a class="kwd-search" href="http://www.biolbull.org/search?fulltext=IIT,+integrated+information+theory&amp;sortspec=date&amp;submit=Submit&amp;andorexactfulltext=phrase">IIT, integrated information theory</a></span></li>
                  <li class="kwd"><span><a class="kwd-search" href="http://www.biolbull.org/search?fulltext=MIP,+minimum+information+partition&amp;sortspec=date&amp;submit=Submit&amp;andorexactfulltext=phrase">MIP, minimum information partition</a></span></li>
               </ul>
               <div class="section" id="sec-1">
                  <div class="section-nav"><a href="#abstract-1" title="Abstract" class="prev-section-link"><span>Previous Section</span></a><a href="#sec-2" title="A Phenomenological Analysis: Consciousness as Integrated Information" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>INTRODUCTION</h2>
                  <p id="p-2">Everybody knows what consciousness is: it 
is what vanishes every night when we fall into dreamless sleep and 
reappears when
                     we wake up or when we dream. It is also all we are 
and all we have: lose consciousness and, as far as you are concerned, 
your
                     own self and the entire world dissolve into 
nothingness.
                  </p>
                  <p id="p-3">Yet almost everybody thinks that 
understanding consciousness at the fundamental level is currently beyond
 the reach of science.
                     The best we can do, it is often argued, is gather 
more and more facts about the neural correlates of consciousness—those 
aspects
                     of brain function that change when some aspects of 
consciousness change—and hope that one day we will come up with an 
explanation.
                     Others are more pessimistic: we may learn all about
 the neural correlates of consciousness and still not understand why 
certain
                     physical processes seem to generate experience 
while others do not.
                  </p>
                  <p id="p-4">It is not that we do not know relevant 
facts about consciousness. For example, we know that the widespread 
destruction of
                     the cerebral cortex leaves people permanently 
unconscious (vegetative), whereas the complete removal of the 
cerebellum, even
                     richer in neurons, hardly affects consciousness. We
 also know that neurons in the cerebral cortex remain active throughout
                     sleep, yet at certain times during sleep 
consciousness fades, while at other times we dream. Finally, we know 
that different
                     parts of the cortex influence different qualitative
 aspects of consciousness: damage to certain parts of the cortex can 
impair
                     the experience of color, whereas other lesions may 
interfere with the perception of shapes. In fact, increasingly refined
                     neuroscientific tools are uncovering increasingly 
precise aspects of the neural correlates of consciousness (<a id="xref-ref-51-1" class="xref-bibr" href="#ref-51">Koch, 2004</a>). And yet, when it comes to <em>explaining why</em> experience blossoms in the cortex and not in the cerebellum, why certain stages of sleep are experientially underprivileged,
                     or why some cortical areas endow our experience with colors and others with sound, we are still at a loss.
                  </p>
                  <p id="p-5">Our lack of understanding is manifested 
most clearly when scientists are asked questions about consciousness in 
“difficult”
                     cases. For example, is a person with akinetic 
mutism—awake with eyes open, but mute, immobile, and nearly 
unresponsive—conscious
                     or not? How much consciousness is there during 
sleepwalking or psychomotor seizures? Are newborn babies conscious, and 
to
                     what extent? Are animals conscious? If so, are some
 animals more conscious than others? Can they feel pain? Does a bat feel
                     space the same way we do? Can bees experience 
colors, or merely react to them? Can a conscious artifact be constructed
 with
                     non-neural ingredients? I believe it is fair to say
 that no consciousness expert, if there is such a job description, can
                     be confident about the correct answer to such 
questions. This is a remarkable state of affairs. Just consider 
comparable questions
                     in physics: Do stars have mass? Do atoms? How many 
different kinds of atoms and elementary particles are there, and of what
                     are they made? Is energy conserved? And how can it 
be measured? Or consider biology: What are species, and how do they 
evolve?
                     How are traits inherited? How do organisms develop?
 How is energy produced from nutrients? How does echolocation work in 
bats?
                     How do bees distinguish among colors? And so on. 
Obviously, we expect satisfactory answers by any competent physicist and
                     biologist.
                  </p>
                  <p id="p-6">What's the matter with consciousness, 
then, and how should we proceed? Early on, I came to the conclusion that
 a genuine understanding
                     of consciousness is possible only if empirical 
studies are complemented by a theoretical analysis. Indeed, 
neurobiological
                     facts constitute both challenging paradoxes and 
precious clues to the enigma of consciousness. This state of affairs is 
not
                     unlike the one faced by biologists when, knowing a 
great deal about similarities and differences between species, fossil 
remains,
                     and breeding practices, they still lacked a theory 
of how evolution might occur. What was needed, then as now, were not 
just
                     more facts, but a theoretical framework that could 
make sense of them.
                  </p>
                  <p id="p-7">In what follows, I discuss the integrated information theory of consciousness (IIT; <a id="xref-ref-65-1" class="xref-bibr" href="#ref-65">Tononi, 2004</a>)—an
 attempt to understand consciousness at the fundamental level. To 
present the theory, I first consider phenomenological
                     thought experiments indicating that subjective 
experience has to do with the generation of integrated information. 
Next, I
                     consider how integrated information can be defined 
mathematically. I then show how basic facts about consciousness and the
                     brain can be accounted for in terms of integrated 
information. Finally, I discuss how the quality of consciousness can be
                     captured geometrically by the shape of 
informational relationships within an abstract space called qualia 
space. I conclude
                     by examining some implications of the theory 
concerning the place of experience in our view of the world.
                  </p>
               </div>
               <div class="section" id="sec-2">
                  <div class="section-nav"><a href="#sec-1" title="INTRODUCTION" class="prev-section-link"><span>Previous Section</span></a><a href="#sec-5" title="A Mathematical Analysis: Quantifying Integrated Information" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>A Phenomenological Analysis: Consciousness as Integrated Information</h2>
                  <p id="p-8">The <em>integrated information theory (IIT)</em> of consciousness claims that, at the fundamental level, consciousness is integrated information, and that its quality is
                     given by the informational relationships generated by a complex of elements (<a id="xref-ref-65-2" class="xref-bibr" href="#ref-65">Tononi, 2004</a>).
 These claims stem from realizing that information and integration are 
the essential properties of our own experience. This
                     may not be immediately evident, perhaps because, 
being endowed with consciousness most of the time, we tend to take its 
gifts
                     for granted. To regain some perspective, it is 
useful to resort to two thought experiments, one involving a photodiode 
and
                     the other a digital camera.
                  </p>
                  <div id="sec-3" class="subsection">
                     <h3>Information: the photodiode thought experiment</h3>
                     <p id="p-9">Consider the following: You are facing a
 blank screen that is alternately on and off, and you have been 
instructed to say
                        “light” when the screen turns on and “dark” when
 it turns off. A photodiode—a simple light-sensitive device—has also 
been
                        placed in front of the screen. It contains a 
sensor that responds to light with an increase in current and a detector
 connected
                        to the sensor that says “light” if the current 
is above a certain threshold and “dark” otherwise. The first problem of 
consciousness
                        reduces to this: when you distinguish between 
the screen being on or off, you have the subjective experience of seeing
 light
                        or dark. The photodiode can also distinguish 
between the screen being on or off, but presumably it does not have a 
subjective
                        experience of light and dark. What is the key 
difference between you and the photodiode?
                     </p>
                     <p id="p-10">According to the IIT, the difference 
has to do with how much information is generated when that distinction 
is made. Information
                        is classically defined as reduction of 
uncertainty: the more numerous the alternatives that are ruled out, the 
greater the
                        reduction of uncertainty, and thus the greater 
the information. It is usually measured using the entropy function, 
which is
                        the logarithm of the number of alternatives 
(assuming they are equally likely). For example, tossing a fair coin and
 obtaining
                        heads corresponds to log<sub>2</sub>(2) = 1 bit of information, because there are just two alternatives; throwing a fair die yields log<sub>2</sub>(6) = 2.59 bits of information, because there are six.
                     </p>
                     <p id="p-11">Let us now compare the photodiode with
 you. When the blank screen turns on, the mechanism in the photodiode 
tells the detector
                        that the current from the sensor is above rather
 than below the threshold, so it reports “light.” In performing this 
discrimination
                        between two alternatives, the detector in the 
photodiode generates log<sub>2</sub>(2) = 1 bit of information. When you
 see the blank screen turn on, on the other hand, the situation is quite
 different. Though
                        you may think you are performing the same 
discrimination between light and dark as the photodiode, you are in fact
 discriminating
                        among a much larger number of alternatives, 
thereby generating many more bits of information.
                     </p>
                     <p id="p-12">This is easy to see. Just imagine 
that, instead of turning light and dark, the screen were to turn red, 
then green, then blue,
                        and then display, one after the other, every 
frame from every movie that was ever produced. The photodiode, 
inevitably, would
                        go on signaling whether the amount of light for 
each frame is above or below its threshold: to a photodiode, things can 
only
                        be one of two ways, so when it reports “light,” 
it really means just “this way” <em>versus</em> “that way.” For you, however, a light screen is different not only from a dark screen, but from a multitude of other images,
                        so when you say “light,” it really means this specific way <em>versus</em>
 countless other ways, such as a red screen, a green screen, a blue 
screen, this movie frame, that movie frame, and so on
                        for every movie frame (not to mention for a 
sound, smell, thought, or any combination of the above). Clearly, each 
frame looks
                        different to you, implying that some mechanism 
in your brain must be able to tell it apart from all the others. So when
 you
                        say “light,” whether you think about it or not 
(and you typically won't), you have just made a discrimination among a 
very
                        large number of alternatives, and thereby 
generated many bits of information.
                     </p>
                     <p id="p-13">This point is so deceivingly simple 
that it is useful to elaborate a bit on why, although a photodiode may 
be as good as we
                        are in detecting light, it cannot possibly see 
light the way we do—in fact, it cannot possibly “see” anything at all. 
Hopefully,
                        by realizing what the photodiode lacks, we may 
appreciate what allows us to consciously “see” the light.
                     </p>
                     <p id="p-14">The key is to realize how the many discriminations we can do, and the photodiode cannot, affect the <em>meaning</em>
 of the discrimination at hand, the one between light and dark. For 
example, the photodiode has no mechanism to discriminate
                        colored from achromatic light, even less to tell
 which particular color the light might be. As a consequence, all light 
is
                        the same to it, as long as it exceeds a certain 
threshold. So for the photodiode, “light” cannot possibly mean 
achromatic
                        as opposed to colored, not to mention of which 
particular color. Also, the photodiode has no mechanism to distinguish 
between
                        a homogeneous light and a bright shape—any 
bright shape—on a darker background. So for the photodiode, light cannot
 possibly
                        mean full field as opposed to a shape—any of 
countless particular shapes. Worse, the photodiode does not even know 
that it
                        is detecting a visual attribute (the 
“visualness” of light) as it has no mechanism to tell visual attributes,
 such as light
                        or dark, from non-visual ones, such as hot and 
cold, light or heavy, loud or soft, and so on. As far as it knows, the 
photodiode
                        might just as well be a thermistor—it has no way
 of knowing whether it is sensing light <em>versus</em> dark or hot <em>versus</em> cold.
                     </p>
                     <p id="p-15">In short, the only specification a 
photodiode can make is whether things are this or that way: any further 
specification is
                        impossible because it does not have mechanisms 
for it. Therefore, when the photodiode detects “light,” such “light” 
cannot
                        possibly mean what it means for us; it does not 
even mean that it is a visual attribute. By contrast, when we see 
“light”
                        in full consciousness, we are implicitly being 
much more specific: we simultaneously specify that things are this way 
rather
                        than that way (light as opposed to dark), that 
whatever we are discriminating is not colored (in any particular color),
 does
                        not have a shape (any particular one), is visual
 as opposed to auditory or olfactory, sensory as opposed to 
thought-like,
                        and so on. To us, then, light is much more 
meaningful precisely because we have mechanisms that can discriminate 
this particular
                        state of affairs we call “light” against a large
 number of alternatives.
                     </p>
                     <p id="p-16">According to the IIT, it is all this added meaning, provided implicitly by <em>how</em>
 we discriminate pure light from all these alternatives, that increases 
the level of consciousness. This central point may
                        be appreciated either by “subtraction” or by 
“addition.” By subtraction, one may realize that our being conscious of 
“light”
                        would degrade more and more—would lose its 
non-coloredness, its non-shapedness, would even lose its visualness—as 
its meaning
                        is progressively stripped down to just “one of 
two ways,” as with the photodiode. By addition, one may realize that we 
can
                        only see “light” as we see it, as progressively 
more and more meaning is added by specifying how it differs from 
countless
                        alternatives. Either way, the theory says that 
the more specifically one's mechanisms discriminate between what pure 
light
                        is and what it is not (the more they specify 
what light means), the more one is conscious of it.
                     </p>
                  </div>
                  <div id="sec-4" class="subsection">
                     <h3>Integration: the camera thought experiment</h3>
                     <p id="p-17">Information—the ability to 
discriminate among a large number of alternatives—may thus be essential 
for consciousness. However,
                        information always implies a point of view, and 
we need to be careful about what that point of view might be. To see 
why,
                        consider another thought experiment, this time 
involving a digital camera, say one whose sensor chip is a collection of
 a
                        million binary photodiodes, each sporting a 
sensor and a detector. Clearly, taken as a whole, the camera's detectors
 could
                        distinguish among 2<sup>1,000,000</sup> 
alternative states, an immense number, corresponding to 1 million bits 
of information. Indeed, the camera would easily respond
                        differently to every frame from every movie that
 was ever produced. Yet few would argue that the camera is conscious. 
What
                        is the key difference between you and the 
camera?
                     </p>
                     <p id="p-18">According to the IIT, the difference has to do with integrated information. From the point of view of an external observer,
                        the camera may be considered as a single system with a repertoire of 2<sup>1,000,000</sup>
 states. In reality, however, the chip is not an integrated entity: 
since its 1 million photodiodes have no way to interact,
                        each photodiode performs its own local 
discrimination between a low and a high current completely independent 
of what every
                        other photodiode might be doing. In reality, the
 chip is just a collection of 1 million independent photodiodes, each 
with
                        a repertoire of two states. In other words, 
there is no intrinsic point of view associated with the camera chip as a
 whole.
                        This is easy to see: if the sensor chip were cut
 into 1 million pieces each holding its individual photodiode, the 
performance
                        of the camera would not change at all.
                     </p>
                     <p id="p-19">By contrast, you discriminate among a 
vast repertoire of states as an integrated system, one that cannot be 
broken down into
                        independent components each with its own 
separate repertoire. Phenomenologically, every experience is an 
integrated whole,
                        one that means what it means by virtue of being 
one, and that is experienced from a single point of view. For example, 
the
                        experience of a red square cannot be decomposed 
into the separate experience of red and the separate experience of a 
square.
                        Similarly, experiencing the full visual field 
cannot be decomposed into experiencing separately the left half and the 
right
                        half: such a possibility does not even make 
sense to us, since experience is always whole. Indeed, the only way to 
split an
                        experience into independent experiences seems to
 be to split the brain in two, as in patients who underwent the section 
of
                        the corpus callosum to treat severe epilepsy (<a id="xref-ref-47-1" class="xref-bibr" href="#ref-47">Gazzaniga, 2005</a>).
 Such patients do indeed experience the left half of the visual field 
independently of the right side, but then the surgery
                        has created two separate consciousnesses instead
 of one. Mechanistically then, underlying the unity of experience must 
be
                        causal interactions among certain elements 
within the brain. This means that these elements work together as an 
integrated
                        system, which is why their performance, unlike 
that of the camera, breaks down if they are disconnected.
                     </p>
                  </div>
               </div>
               <div class="section" id="sec-5">
                  <div class="section-nav"><a href="#sec-2" title="A Phenomenological Analysis: Consciousness as Integrated Information" class="prev-section-link"><span>Previous Section</span></a><a href="#sec-9" title="A Neurobiological Reality Check: Accounting for Empirical Observations" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>A Mathematical Analysis: Quantifying Integrated Information</h2>
                  <p id="p-20">This phenomenological analysis suggests that, to generate consciousness, a physical system must be able to discriminate among
                     a large repertoire of states (information) <em>and</em>
 it must be unified; that is, it should be doing so as a single system, 
one that is not decomposable into a collection of
                     causally independent parts (integration). But how 
can one measure integrated information? As I explain below, the central
                     idea is to quantify the information generated by a 
system, above and beyond the information generated independently by its
                     parts (<a id="xref-ref-64-1" class="xref-bibr" href="#ref-64">Tononi, 2001</a>, <a id="xref-ref-65-3" class="xref-bibr" href="#ref-65">2004</a>; <a id="xref-ref-36-1" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).<sup><a id="xref-ref-1-1" class="xref-bibr" href="#ref-1">1</a></sup></p>
                  <div id="sec-6" class="subsection">
                     <h3>Information</h3>
                     <p id="p-21">First, we must evaluate how much information is generated by the system. Consider the system of two binary units in <a id="xref-fig-1-1" class="xref-fig" href="#F1">Figure 1</a>,
 which can be thought of as an idealized version of a photodiode 
composed of a sensor S and a detector D. The system is characterized
                        by a state it is in, which in this case is 11 
(first digit for the sensor, second digit for the detector), and by a 
mechanism.
                        This is mediated by a connection (arrow) between
 the sensor and the detector that implements a causal interaction: in 
this
                        case, the elementary mechanism of the system is 
that the detector checks the state of the sensor and turns on if the 
sensor
                        is on, and off otherwise (more generally, the 
specific causal interaction can be described by an input-output table).
                     </p>
                     <div id="F1" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F1.expansion.html"><img alt="Figure 1." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F1.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F1.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F1.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 1.</span> 
                           <p id="p-121" class="first-child"><strong>Effective information</strong>.
 (A) A “photodiode” consisting of a sensor and detector unit. The 
photodiode's mechanism is such that the detector unit turns
                              on if the sensor's current is above a 
threshold. Here both units are on (binary 1, indicated in gray). (B) For
 the entire
                              system (sensor unit, detector unit) there 
are four possible states: (00,01,10,11). The potential distribution p(X<sub>0</sub>(maxH))
 = (1/4,1/4,1/4,1/4) is the maximum entropy distribution on the four 
states. Given the photodiode's mechanism and the
                              fact that the detector is on, the sensor 
must have been on. Thus, the photodiode's mechanism and its current 
state specifies
                              the following distribution: two of the 
four possible states (00,01) are ruled out; the other two states (10,11)
 are equally
                              likely since they are indistinguishable to
 the mechanism (the prior state of the detector makes no difference to 
the current
                              state of the sensor). The actual 
distribution is therefore p(X<sub>0</sub>(mech, x<sub>1</sub>)) = (0,0,1/2,1/2). Relative entropy (Kullback-Leibler divergence) between two probability distributions <em>p</em> and <em>q</em> is H[p|q] = p<sub>i</sub> log<sub>2</sub> p<sub>i</sub>/q<sub>i</sub>, so the effective information ei(X(mech, x<sub>1</sub>)) associated with output x<sub>1</sub> = 11 is 1 bit (effective information is the entropy of the actual relative to the potential distributions).
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-22">Potentially, a system of two binary elements could be in any of four possible states (00,01,10,11) with equal probability:
                        p = (1/4,1/4,1/4,1/4). Formally, this <em>potential</em> (<em>a priori</em>)
 repertoire is represented by the maximum entropy or uniform 
distribution of possible system states at time t=0, which expresses
                        complete uncertainty (p(X<sub>0</sub>(maxH))). Considering the potential repertoire as the set of all possible input states, the particular mechanism X(mech) of
                        this system can be thought of as specifying a <em>forward</em> repertoire—the probability distribution of output states produced by the system when perturbed with all possible input states.
                        But the system is actually in a particular output state (in this case, at time t=1, x<sub>1</sub> = 11). In actuality, a system with this mechanism being in state 11 <em>specifies</em> that the previous system state x<sub>0</sub>
 must have been either 11 or 10, rather than 00 or 01, corresponding to p
 = (0,0,1/2,1/2) (in this system, there is no mechanism
                        to specify the detector state, which remains 
uncertain). Formally, then, the mechanism and the state 11 specify an <em>actual</em> (<em>a posteriori</em>) distribution or repertoire of system states p(X<sub>0</sub>(mech,x<sub>1</sub>)) at time t=0 that could have caused (led to) x<sub>1</sub>
 at time t=1, while ruling out (giving probability zero to) states that 
could not. In this way, the system's mechanism and
                        state constitute information (about the system's
 previous state), in the classic sense of reduction of uncertainty or 
ignorance.
                        More precisely, the system's mechanism and state
 generate 1 bit of information by distinguishing between things being 
one
                        way (11 or 10, which remain indistinguishable to
 it) rather than another way (00 or 01, which also remain 
indistinguishable
                        to it).
                     </p>
                     <p id="p-23">In general, the information generated when a system characterized by a certain mechanism in a particular state can be measured
                        by the <em>relative entropy</em> H between the actual and the potential repertoires (“relative to” is indicated by ‖), captured by the <em>effective information</em> (ei): <span class="disp-formula" id="disp-formula-1"><img class="math tex" alt="Formula" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/tex-math-1.gif"></span> Relative entropy, also known as Kullback-Leibler divergence, is a difference between probability distributions (<a id="xref-ref-41-1" class="xref-bibr" href="#ref-41">Cover and Thomas, 2006</a>): if the distributions are identical, relative entropy is zero; the more different they are, the higher the relative entropy.<sup><a id="xref-ref-2-1" class="xref-bibr" href="#ref-2">2</a></sup>
 Figuratively, the system's mechanism and state generate information by 
sharpening the uniform distribution into a less uniform
                        one—this is how much uncertainty is reduced. 
Clearly, the amount of effective information generated by a system is 
high if
                        it has a large potential repertoire and a small 
actual repertoire, since a large number of initial states are ruled out.
 By
                        contrast, the information generated is little if
 the system's repertoire is small, or if many states could lead to the 
current
                        outcome, since few states are ruled out. For 
instance, if noise dominates (any state could have led to the current 
one), no
                        alternatives are ruled out, and no information 
is generated.
                     </p>
                     <p id="p-24">Since effective information is 
implicitly specified once a mechanism and state are specified, it can be
 considered to be an
                        “intrinsic” property of a system. To calculate 
it explicitly, from an extrinsic perspective, one can perturb the system
 in
                        all possible ways (<em>i.e</em>., try out all 
possible input states, corresponding to the maximum entropy distribution
 or potential repertoire) to obtain
                        the forward repertoire of output states given 
the system's mechanism. Finally one can calculate, using Bayes’ rule, 
the actual
                        repertoire given the system's state (<a id="xref-ref-36-2" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).<sup><a id="xref-ref-3-1" class="xref-bibr" href="#ref-3">3</a></sup></p>
                  </div>
                  <div id="sec-7" class="subsection">
                     <h3>Integration</h3>
                     <p id="p-25">Second, we must find out how much of 
the information generated by a system is integrated information; that 
is, how much information
                        is generated by a single entity, as opposed to a
 collection of independent parts. The idea here is to consider the parts
 of
                        the system independently, ask how much 
information they generate by themselves, and compare it with the 
information generated
                        by the system as a whole.
                     </p>
                     <p id="p-26">This can be done by resorting again to relative entropy to measure the difference between the probability distribution generated
                        by the system as a whole (p(X<sub>0</sub>(mech,x<sub>1</sub>)), the actual repertoire of the system x) with the probability distribution generated by the parts considered independently
                        (Πp(<sup>k</sup>M<sub>0</sub>(mech,μ<sub>1</sub>)), the product of the actual repertoire of the parts <sup>k</sup>M). Integrated information is indicated with the symbol Φ (the vertical bar “I” stands for information, the circle “O” for
                        integration): <span class="disp-formula" id="disp-formula-2"><img class="math tex" alt="Formula" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/tex-math-2.gif"></span>
 That is, the actual repertoire for each part is specified by causal 
interactions internal to each part, considered as a system
                        in its own right, while external inputs are 
treated as a source of extrinsic noise. The comparison is made with the 
particular
                        decomposition of the system into parts that 
leaves the least information unaccounted for. This <em>minimum information partition</em> (MIP) decomposes the system into its <em>minimal parts</em>.
                     </p>
                     <p id="p-27">To see how this works, consider two of the million photodiodes in the digital camera (<a id="xref-fig-2-1" class="xref-fig" href="#F2">Fig. 2</a>,
 left). By turning on or off depending on its input, each photodiode 
generates 1 bit of information, just as we saw before.
                        Considered independently, then, two photodiodes 
generate 2 bits of information, and 1 million photodiodes generate 1 
million
                        bits of information. However, as shown in the 
figure, the product of the actual distributions generated independently 
by the
                        parts is identical to the actual distribution 
for the system. Therefore, the relative entropy between the two 
distributions
                        is zero: the system generates no integrated 
information (Φ (X(mech,x<sub>1</sub>)) = 0) above and beyond what is generated by its parts.
                     </p>
                     <div id="F2" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F2.expansion.html"><img alt="Figure 2." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F2.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F2.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F2.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 2.</span> 
                           <p id="p-122" class="first-child"><strong>Integrated information</strong>. <em>Left-hand side:</em> two photodiodes in a digital camera. (A) Information generated by the system as a whole. The system as a whole generates
                              2 bits of effective information by specifying that n<sub>1</sub> and n<sub>3</sub>
 must have been on. (B) Information generated by the parts. The minimum 
information partition (MIP) is the decomposition of
                              a system into (minimal) parts, that is, 
the decomposition that leaves the least information unaccounted for. 
Here the parts
                              are two photodiodes. (C) The information 
generated by the system as a whole is completely accounted for by the 
information
                              generated by its parts. In this case, the 
actual repertoire of the whole is identical to the combined actual 
repertoires of
                              the parts (the product of their respective
 probability distributions), so that relative entropy is zero. The 
system generates
                              no information above and beyond the parts,
 so it cannot be considered a single entity. <em>Right-hand side:</em> an integrated system. Elements in the system are on if they receive two or more spikes. The system is in state x<sub>1</sub> = 1000. (A′) The mechanism specifies a unique prior state that can cause state x<sub>1</sub>,
 so the system generates 4 bits of effective information. All other 
initial states are ruled out, since they cause different
                              outputs. (B′) Effective information 
generated by the two minimal parts, considered as systems in their own 
right. External
                              inputs are treated as extrinsic noise. 
(C′) Integrated information is information generated by the whole (black
 arrows) over
                              and above the parts (gray arrows). In this
 case, the actual repertoire of the whole is different from the combined
 actual
                              repertoires of the parts, and the relative
 entropy is 2 bits. The system generates information above and beyond 
the parts,
                              so it can be considered a single entity (a
 complex).
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-28">Clearly, for integrated information to be high, a system must be connected in such a way that information is generated by
                        causal interactions <em>among</em> rather than <em>within</em>
 its parts. Thus, a system can generate integrated information only to 
the extent that it cannot be decomposed into informationally
                        independent parts. A simple example of such a 
system is shown in <a id="xref-fig-2-2" class="xref-fig" href="#F2">Figure 2</a> (right). In this case, the interaction between the minimal parts of the system generates information above and beyond what
                        is accounted for by the parts by themselves (Φ (X(mech,x<sub>1</sub>)) &gt; 0).
                     </p>
                     <p id="p-29">In short, integrated information captures the information generated by causal interactions in the whole, over and above the
                        information generated by the parts.<sup><a id="xref-ref-4-1" class="xref-bibr" href="#ref-4">4</a></sup></p>
                  </div>
                  <div id="sec-8" class="subsection">
                     <h3>Complexes</h3>
                     <p id="p-30">Finally, by measuring Φ values for all subsets of elements within a system, we can determine which subsets form <em>complexes</em>. Specifically, a complex X is a set of elements that generate integrated information (Φ &gt; 0) that is not fully contained
                        in some larger set of higher Φ (<a id="xref-fig-3-1" class="xref-fig" href="#F3">Fig. 3</a>).
 A complex, then, can be properly considered to form a single entity 
having its own, intrinsic “point of view” (as opposed
                        to being treated as a single entity from an 
outside, extrinsic point of view). Since integrated information is 
generated <em>within</em> a complex and not outside its boundaries, 
experience is necessarily private and related to a single point of view 
or perspective
                        (<a id="xref-ref-66-1" class="xref-bibr" href="#ref-66">Tononi and Edelman, 1998</a>; <a id="xref-ref-65-4" class="xref-bibr" href="#ref-65">Tononi, 2004</a>). A given physical system, such as a brain, is likely to contain more than one complex, many small ones with low Φ values,
                        and perhaps a few large ones (<a id="xref-ref-66-2" class="xref-bibr" href="#ref-66">Tononi and Edelman, 1998</a>; <a id="xref-ref-65-5" class="xref-bibr" href="#ref-65">Tononi, 2004</a>). In fact, at any given time there may be a single <em>main complex</em> of comparatively much higher Φ that underlies the dominant experience (a main complex is such that its subsets have strictly
                        lower Φ). As shown in <a id="xref-fig-3-2" class="xref-fig" href="#F3">Figure 3</a>, a main complex can be embedded into larger complexes of lower Φ. Thus, a complex can be casually connected, through <em>ports-in</em> and <em>ports-out</em>, to elements that are not part of it. According to the IIT, such elements can indirectly influence the state of the main
                        complex without contributing directly to the conscious experience it generates (<a id="xref-ref-68-1" class="xref-bibr" href="#ref-68">Tononi and Sporns, 2003</a>).
                     </p>
                     <div id="F3" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F3.expansion.html"><img alt="Figure 3." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F3.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F3.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F3.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 3.</span> 
                           <p id="p-123" class="first-child"><strong>Complexes</strong>.
 In this system, the mechanism is that elements fire in response to an 
odd number of spikes on their afferent connections
                              (links without arrows are bidirectional 
connections). Analyzing the system in terms of integrated information 
shows that the
                              system constitutes a complex (x, light 
gray) that contains three smaller complexes (s,a,b, in different shades 
of gray). Observe
                              that <em>(i)</em> complexes can overlap; <em>(ii)</em> a complex can interact causally with elements not part of it; <em>(iii)</em> groups of elements with identical architectures (a and b) generate different amounts of integrated information, depending
                              on their ports-in and ports-out.
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="section" id="sec-9">
                  <div class="section-nav"><a href="#sec-5" title="A Mathematical Analysis: Quantifying Integrated Information" class="prev-section-link"><span>Previous Section</span></a><a href="#sec-10" title="The Quality of Consciousness: Characterizing Informational Relationships" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>A Neurobiological Reality Check: Accounting for Empirical Observations</h2>
                  <p id="p-31">Can this approach account, at least in 
principle, for some of the basic facts about consciousness that have 
emerged from decades
                     of clinical and neurobiological observations? 
Measuring Φ and finding complexes is not easy for realistic systems, but
 it
                     can be done for simple networks that bear some 
structural resemblance to different parts of the brain (<a id="xref-ref-65-6" class="xref-bibr" href="#ref-65">Tononi, 2004</a>; <a id="xref-ref-36-3" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
                  </p>
                  <p id="p-32">For example, by using computer 
simulations, it is possible to show that high Φ requires networks that 
conjoin functional specialization
                     (due to its specialized connectivity; each element 
has a unique functional role within the network) with functional 
integration
                     (there are many pathways for interactions among the
 elements, <a id="xref-fig-4-1" class="xref-fig" href="#F4">Fig. 4A</a>.).
 In very rough terms, this kind of architecture is characteristic of the
 mammalian corticothalamic system: different parts
                     of the cerebral cortex are specialized for 
different functions, yet a vast network of connections allows these 
parts to interact
                     profusely. And indeed, as much neurological 
evidence indicates (<a id="xref-ref-59-1" class="xref-bibr" href="#ref-59">Posner and Plum, 2007</a>), the corticothalamic system is precisely the part of the brain that cannot be severely impaired without loss of consciousness.
                  </p>
                  <div id="F4" class="fig pos-float odd">
                     <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F4.expansion.html"><img alt="Figure 4." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F4.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                              <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F4.expansion.html">In this page</a></li>
                              <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F4.expansion.html">In a new window</a></li>
                           </ul>
                           <ul class="fig-services"></ul>
                        </div>
                     </div>
                     <div class="fig-caption"><span class="fig-label">Figure 4.</span> 
                        <p id="p-124" class="first-child"><strong>Relating integrated information to neuroanatomy and neurophysiology</strong>.
 Elements fire in response to two or more spikes (except elements 
targeted by a single connection, which copy their input);
                           links without arrows are bidirectional. (A) 
Computing Φ in simple models of neuroanatomy suggests that a 
functionally integrated
                           and functionally specialized network—like the
 corticothalamic system—is well suited to generating high values of Φ. 
(B, C,
                           D) Architectures modeled on the cerebellum, 
afferent pathways, and cortical-subcortical loops give rise to complexes
 containing
                           more elements, but with reduced Φ compared to
 the main corticothalamic complex. (E) Φ peaks in balanced states; if 
too many
                           or too few elements are active, Φ collapses. 
(F) In a bistable (“sleeping”) system (same as in (E)), Φ collapses when
 the
                           number of firing elements (dotted line) is 
too high (high % activity), remains low during the “DOWN” state (zero % 
activity),
                           and only recovers at the onset of the next 
“UP” state.
                        </p>
                        <div class="sb-div caption-clear"></div>
                     </div>
                  </div>
                  <p id="p-33">Conversely, Φ is low for systems that are made up of small, quasi-independent modules (<a id="xref-fig-4-2" class="xref-fig" href="#F4">Fig. 4B</a>; <a id="xref-ref-65-7" class="xref-bibr" href="#ref-65">Tononi, 2004</a>; <a id="xref-ref-36-4" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
 This may be why the cerebellum, despite its large number of neurons, 
does not contribute much to consciousness: its synaptic
                     organization is such that individual patches of 
cerebellar cortex tend to be activated independently of one another, 
with
                     little interaction between distant patches (<a id="xref-ref-40-1" class="xref-bibr" href="#ref-40">Bower, 2002</a>).
                  </p>
                  <p id="p-34">Computer simulations also show that units along multiple, segregated incoming or outgoing pathways are not incorporated within
                     the repertoire of the main complex (<a id="xref-fig-4-3" class="xref-fig" href="#F4">Fig. 4C</a>; <a id="xref-ref-65-8" class="xref-bibr" href="#ref-65">Tononi, 2004</a>; <a id="xref-ref-36-5" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
 This may be why neural activity in afferent pathways (perhaps as far as
 V1), though crucial for triggering this or that
                     conscious experience, does not contribute directly 
to conscious experience; nor does activity in efferent pathways (perhaps
                     starting with primary motor cortex), though it is 
crucial for reporting each different experience.
                  </p>
                  <p id="p-35">The addition of many parallel cycles also generally does not change the composition of the main complex, although Φ values
                     can be altered (<a id="xref-fig-4-4" class="xref-fig" href="#F4">Fig. 4D</a>).
 Instead, cortical and subcortical cycles or loops implement specialized
 subroutines that are capable of influencing the
                     states of the main corticothalamic complex without 
joining it. Such informationally insulated cortico-subcortical loops 
could
                     constitute the neural substrates for many 
unconscious processes that can affect and be affected by conscious 
experience (<a id="xref-ref-34-1" class="xref-bibr" href="#ref-34">Baars, 1988</a>; <a id="xref-ref-65-9" class="xref-bibr" href="#ref-65">Tononi, 2004</a>), such as those that enable object recognition, language parsing, or translating our vague intentions into the right words.
                  </p>
                  <p id="p-36">At this stage, it is hard to say 
precisely which cortical circuits may work as a large complex of high Φ,
 and which instead
                     may remain informationally insulated. Does the 
dense mesial connectivity revealed by diffusion spectral imaging (<a id="xref-ref-48-1" class="xref-bibr" href="#ref-48">Hagmann <em>et al</em>., 2008</a>)
 constitute the “backbone” of a corticothalamic main complex? Do 
parallel loops through basal ganglia implement informationally
                     insulated subroutines? Are primary sensory cortices
 organized like massive afferent pathways to a main complex higher up in
                     the cortical hierarchy (<a id="xref-ref-51-2" class="xref-bibr" href="#ref-51">Koch, 2004</a>)?
 Is much of prefrontal cortex organized like a massive efferent pathway?
 Do certain cortical areas, such as those belonging
                     to the dorsal visual stream, remain partly 
segregated from the main complex? Unfortunately, answering these 
questions and
                     properly testing the predictions of the theory 
requires a much better understanding of cortical neuroanatomy than is 
currently
                     available.
                  </p>
                  <p id="p-37">Other simulations show that the effects of cortical disconnections are readily captured in terms of integrated information
                     (<a id="xref-ref-65-10" class="xref-bibr" href="#ref-65">Tononi, 2004</a>):
 a “callosal” cut produces, out of a large complex corresponding to the 
connected corticothalamic system, two separate complexes,
                     in line with many studies of split-brain patients (<a id="xref-ref-47-2" class="xref-bibr" href="#ref-47">Gazzaniga, 2005</a>).
 However, because there is great redundancy between the two hemispheres,
 their Φ value is not greatly reduced compared to
                     when they form a single complex. Functional 
disconnections may also lead to a restriction of the neural substrate of
 consciousness,
                     as is seen in neurological neglect phenomena, in 
psychiatric conversion and dissociative disorders, and possibly during 
dreaming
                     and hypnosis. It is also likely that certain 
attentional phenomena may correspond to changes in the composition of 
the main
                     complex underlying consciousness (<a id="xref-ref-53-1" class="xref-bibr" href="#ref-53">Koch and Tsuchiya, 2007</a>). The attentional blink,<sup><a id="xref-ref-5-1" class="xref-bibr" href="#ref-5">5</a></sup>
 where a fixed sensory input may at times make it to consciousness and 
at times not, may also be due to changes in functional
                     connectivity: access to the main corticothalamic 
complex may be enabled or not based on dynamics intrinsic to the complex
                     (<a id="xref-ref-43-1" class="xref-bibr" href="#ref-43">Dehaene <em>et al</em>., 2003</a>). Similarly, binocular rivalry<sup><a id="xref-ref-6-1" class="xref-bibr" href="#ref-6">6</a></sup>
 may be related, at least in part, to dynamic changes in the composition
 of the main corticothalamic complex caused by transient
                     changes in functional connectivity. Computer 
simulations confirm that functional disconnection can reduce the size of
 a complex
                     and reduce its capacity to integrate information (<a id="xref-ref-65-11" class="xref-bibr" href="#ref-65">Tononi, 2004</a>).
 While it is not easy to determine, at present, whether a particular 
group of neurons is excluded from the main complex
                     because of hard-wired anatomical constraints or is 
transiently disconnected due to functional changes, the set of elements
                     underlying consciousness is not static, but form a “<em>dynamic complex</em>” or “<em>dynamic core</em>” (<a id="xref-ref-66-3" class="xref-bibr" href="#ref-66">Tononi and Edelman, 1998</a>).
                  </p>
                  <p id="p-38">Computer simulations also indicate that the capacity to integrate information is reduced if neural activity is extremely high
                     and near-synchronous, due to a dramatic decrease in the repertoire of discriminable states (<a id="xref-fig-4-5" class="xref-fig" href="#F4">Fig. 4E</a>; <a id="xref-ref-36-6" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>). This reduction in degrees of freedom could be the reason that consciousness is reduced or eliminated in absence seizure
                     (petit mal) and other conditions during which neural activity is both high and synchronous (<a id="xref-ref-39-1" class="xref-bibr" href="#ref-39">Blumenfeld and Taylor, 2003</a>).
                  </p>
                  <p id="p-39">The most common example of a marked 
change in the level of experience is the fading of consciousness that 
occurs during certain
                     periods of sleep. Subjects awakened in deep NREM 
(non–rapid eye movement) sleep, especially early in the night, often 
report
                     that they were not aware of themselves or of 
anything else, though cortical and thalamic neurons remain active. 
Awakened at
                     other times, mainly during REM sleep or during 
lighter periods of NREM sleep later in the night, they report dreams 
characterized
                     by vivid images (<a id="xref-ref-49-1" class="xref-bibr" href="#ref-49">Hobson <em>et al</em>., 2000</a>).
 From the perspective of integrated information, a reduction of 
consciousness during early sleep would be consistent with
                     the bistability of cortical circuits during deep 
NREM sleep. Due to changes in intrinsic and synaptic conductances 
triggered
                     by neuromodulatory changes (<em>e.g</em>., low acetylcholine), cortical neurons cannot sustain firing for more than a few hundred milliseconds and invariably enter
                     a hyperpolarized down-state. Shortly afterward, they inevitably return to a depolarized up-state (<a id="xref-ref-63-1" class="xref-bibr" href="#ref-63">Steriade <em>et al</em>., 2001</a>). Indeed, computer simulations show that values of Φ are low in systems with such bistable dynamics (<a id="xref-fig-4-6" class="xref-fig" href="#F4">Fig. 4F</a>, <a id="xref-ref-36-7" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
 Consistent with these observations, studies using TMS, a technique for 
stimulating the brain non-invasively, in conjunction
                     with high-density EEG, show that early NREM sleep 
is associated either with a breakdown of the effective connectivity 
among
                     cortical areas, and thereby with a loss of 
integration (<a id="xref-ref-54-1" class="xref-bibr" href="#ref-54">Massimini <em>et al</em>., 2005</a>, <a id="xref-ref-55-1" class="xref-bibr" href="#ref-55">2007</a>), or with a stereotypical global response suggestive of a loss of repertoire and thus of information (<a id="xref-ref-55-2" class="xref-bibr" href="#ref-55">Massimini <em>et al</em>., 2007</a>). Similar changes are seen in animal studies of anesthesia (<a id="xref-ref-33-1" class="xref-bibr" href="#ref-33">Alkire <em>et al</em>., 2008</a>).
                  </p>
                  <p id="p-40">Finally, consciousness not only requires a neural substrate with appropriate anatomical structure and appropriate physiological
                     parameters, it also needs time (<a id="xref-ref-35-1" class="xref-bibr" href="#ref-35">Bachmann, 2000</a>).
 The theory predicts that the time requirement for the generation of 
conscious experience in the brain emerges directly
                     from the time requirements for the build-up of an 
integrated repertoire among the elements of the corticothalamic main 
complex
                     so that discriminations can be highly informative (<a id="xref-ref-65-12" class="xref-bibr" href="#ref-65">Tononi, 2004</a>;
 Balduzzi and Tononi, unpubl.). To give an obvious example, if one were 
to perturb half of the elements of the main complex
                     for less than a millisecond, no perturbations would
 produce any effect on the other half within this time window, and Φ 
would
                     be zero. After, say, 100 ms, however, there is 
enough time for differential effects to be manifested, and Φ should 
grow.
                  </p>
               </div>
               <div class="section" id="sec-10">
                  <div class="section-nav"><a href="#sec-9" title="A Neurobiological Reality Check: Accounting for Empirical Observations" class="prev-section-link"><span>Previous Section</span></a><a href="#sec-14" title="A Provisional Manifesto" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>The Quality of Consciousness: Characterizing Informational Relationships</h2>
                  <p id="p-41">If the amount of integrated information 
generated by different brain structures (or by the same structure 
functioning in different
                     ways) can in principle account for changes in the 
level of consciousness, what is responsible for the quality of each 
particular
                     experience? What determines that colors look the 
way they do and are different from the way music sounds? Once again, 
empirical
                     evidence indicates that different qualities of 
consciousness must be contributed by different cortical areas. Thus, 
damage
                     to certain parts of the cerebral cortex forever 
eliminates our ability to experience color (whether perceived, imagined,
 remembered,
                     or dreamt), whereas damage to other parts 
selectively eliminates our ability to experience visual shapes. There is
 obviously
                     something about different parts of the cortex that 
can account for their different contribution to the quality of 
experience.
                     What is this something?
                  </p>
                  <p id="p-42">The IIT claims that, just as the <em>quantity</em> of consciousness generated by a complex of elements is determined by the amount of integrated information it generates above
                     and beyond its parts, the <em>quality</em> of consciousness is determined by the set of all the informational relationships its mechanisms generate. That is, <em>how</em> integrated information is generated within a complex determines not only the amount of consciousness it has, but also what
                     kind of consciousness.
                  </p>
                  <p id="p-43">Consider again the photodiode thought 
experiment. As I discussed before, when the photodiode reacts to light, 
it can only
                     tell that things are one way rather than another 
way. On the other hand, when we see “light,” we discriminate against 
many
                     more states of affairs, and thus generate much more
 information. In fact, I argued that “light” means what it means and 
becomes
                     conscious “light” <em>by virtue of</em> being not just the opposite of dark, but also different from any color, any shape, any combination of colors and shapes,
                     any frame of every possible movie, any sound, smell, thought, and so on.
                  </p>
                  <p id="p-44">What needs to be emphasized at this point
 is that discriminating “light” against all these alternatives implies 
not just picking
                     one thing out of “everything else” (an 
undifferentiated bunch), but distinguishing at once, in a specific way, 
between each
                     and every alternative. Consider a very simple 
example: a binary counter capable of discriminating among the four 
numbers:
                     00, 01, 10, 11. When the counter says binary “3,” 
it is not just discriminating 11 from everything else as an 
undifferentiated
                     bunch, otherwise it would not be a counter, but a 
11 detector. To be a counter, the system must be able to tell 11 apart 
from
                     00 as well as from 10 as well as from 01 in 
different, specific ways. It does so, of course, by making choices 
through its
                     mechanisms; for example: is this the first or the 
second digit? Is it a 0 or a 1? Each mechanism adds its specific 
contribution
                     to the discrimination they perform together. 
Similarly, when we see light, mechanisms in our brain are not just 
specifying
                     “light” with respect to a bunch of undifferentiated
 alternatives. Rather, these mechanisms are specifying that light is 
what
                     it is by virtue of being different, in this and 
that specific way, from every other alternative—from dark to any color, 
to
                     any shape, movie frame, sound or smell, and so on.
                  </p>
                  <p id="p-45">In short, generating a large amount of 
integrated information entails having a highly structured set of 
mechanisms that allow
                     us to make many nested discriminations (choices) as
 a single entity. According to the IIT, these mechanisms working 
together
                     generate integrated information by specifying a set
 of informational relationships that completely and univocally determine
                     the quality of experience.
                  </p>
                  <div id="sec-11" class="subsection">
                     <h3>Experience as a shape in qualia space</h3>
                     <p id="p-46">To see how this intuition can be given a mathematical formulation, let us consider again a complex of <em>n</em> binary elements X(mech,x<sub>1</sub>)
 having a particular mechanism and being in a particular state. The 
mechanism of the system is implemented by a set of connections
                        X<sup>conn</sup> among its elements. Let us now suppose that each possible state of the system constitutes an axis or dimension of a <em>qualia space</em> (Q) having 2<sup>n</sup> dimensions. Each axis is labeled with the probability p for that state, going from 0 to 1, so that a repertoire (<em>i.e</em>., a probability distribution on the possible states of the complex) corresponds to a point in Q (<a id="xref-fig-5-1" class="xref-fig" href="#F5">Fig. 5</a>).
                     </p>
                     <div id="F5" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F5.expansion.html"><img alt="Figure 5." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F5.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F5.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F5.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 5.</span> 
                           <p id="p-125" class="first-child"><strong>Qualia</strong>. (A) The system in the inset is the same as in <a id="xref-fig-2-5" class="xref-fig" href="#F2">Fig. 2A</a>′.
 Qualia (Q)-space for a system of four units is 16-dimensional (one axis
 per possible state; since axes are displayed flattened
                              onto the page, and points and arrows 
cannot be properly drawn in 2-dimensions, their position and direction 
is for illustration
                              only). In state x<sub>1</sub> = 1000, the 
complex generates a quale or shape in Q, as follows. The maximum entropy
 distribution (the “bottom” of the quale,
                              indicated by a black square) is a point 
assigning equal probability (p = 1/16 = 0.0625) to all 16 system states,
 close to
                              the origin of the 16-dimensional space. 
Engaging a single connection “r” between elements 4 and 3 (c<sub>43</sub>) specifies that, since element n<sub>3</sub> has not fired, the probability of element n<sub>4</sub> having fired in the previous time step is reduced to p = 0.25 compared to its maximum entropy value (p = 0.5), while the
                              probability of n<sub>4</sub> not having 
fired is increased to p = 0.75. The actual probability distribution of 
the 16 system states is modified accordingly.
                              Thus, the connection r “sharpens” the 
maximum entropy distribution into an actual distribution, which is 
another point in
                              Q. The <em>q-arrow</em> linking the two distributions geometrically realizes the <em>informational relationship</em> specified by the connection. The length (divergence) of the q-arrow expresses <em>how much</em>
 the connection specifies the distribution (the effective information it
 generates or relative entropy between the two distributions);
                              the direction in Q expresses <em>the particular way</em>
 in which the connection specifies the distribution. (B) Engaging more 
connections further sharpens the actual repertoire,
                              specifying new points in Q and the 
corresponding q-arrows. The figure shows 16 out of the 399 points in the
 quale, generated
                              by combinations of the four sets of 
connections. The probability distributions depicted around the quale are
 representative
                              of the repertoires generated by two 
q-edges formed by q-arrows that engage the four sets of connections in 
two different orders
                              (the two representative q-edges start at 
bottom left—one goes clockwise, the other counter-clockwise; black 
connections represent
                              those whose contribution is being 
evaluated; gray connections those whose contribution has already been 
considered and which
                              provides the context on top of which the 
q-arrow generated by a black connection begins). Repertoires 
corresponding to certain
                              points of the quale are shown alongside, 
as in previous figures. Effective information values (in bits) of the 
q-arrows in
                              the two q-edges are shown alongside. 
Together, the q-edges enclose a shape, the quale, which completely 
specifies the quality
                              of the experience.
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-47">Let us now examine how the connections
 among the elements of the complex specify probability distributions; 
that is, how a
                        set of mechanisms specifies a set of 
informational relationships. First, consider the complex with all 
connections among its
                        elements disengaged, thus discounting any causal
 interactions (<a id="xref-fig-5-2" class="xref-fig" href="#F5">Fig. 5A</a>). In the absence of a mechanism, the state x<sub>1</sub>
 provides no information about the system's previous state: from the 
perspective of a system without causal interactions,
                        all previous states are equally likely, 
corresponding to the maximum entropy or uniform distribution (the 
potential repertoire).
                        In Q, this probability distribution is a point 
projecting onto all axes at p = 1/2<sup>n</sup> (probabilities must sum to 1).
                     </p>
                     <p id="p-48">Next, consider engaging a single connection (<a id="xref-fig-5-3" class="xref-fig" href="#F5">Fig. 5A</a>, the other connections are treated as extrinsic noise). As with the photodiode, the mechanism implemented by that connection
                        and the state the system is in rule out states that could not have caused x<sub>1</sub> and increases the actual probability of states that could have caused x<sub>1</sub>,
 yielding an actual repertoire. In Q, the actual repertoire specified by
 this connection corresponds to a point projecting
                        onto higher p values on some axes and onto lower
 p values (or zero) on other axes. Thus, the connection shapes the 
uniform
                        distribution into a more specific distribution, 
and thereby generates information (reduces uncertainty). More generally,
 we
                        can say that the connection specifies an <em>informational relationship</em>, that is, a relationship between two probability distributions. This informational relationship can be represented as an
                        arrow in Q (<em>q-arrow</em>) that goes from the point corresponding to the maximum entropy distribution (p = 1/2<sup>n)</sup> to the point corresponding to the actual repertoire specified by that connection. The length (divergence) of the q-arrow
                        expresses <em>how much</em> the connection specifies the distribution (the effective information it generates, <em>i.e</em>., the relative entropy between the two distributions); the direction in Q expresses <em>the particular way</em> in which the connection specifies the distribution, <em>i.e</em>., a change in position in Q. Similarly, if one considers all other connections taken in isolation, each will specify another
                        q-arrow of a certain length, pointing in a different direction.
                     </p>
                     <p id="p-49">Next, consider all possible combinations of connections (<a id="xref-fig-5-4" class="xref-fig" href="#F5">Fig. 5B</a>). For instance, consider adding the contribution of the second connection to that of the first. Together, the first and second
                        connections specify another actual <em>repertoire</em>—another
 point in Q-space—and thereby generate more information than either 
connection alone as they shape the uniform distribution
                        into a more specific distribution. To the tip of
 the q-arrow specified by the first connection, one can now add a 
q-arrow
                        bent in the direction contributed by the second 
connection, forming an “edge” of two q-arrows in Q-space (the same final
 point
                        is reached by adding the q-arrow due to the 
first connection on top of the q-arrow specified by the second one). 
Each combination
                        of connection therefore specifies a <em>q-edge</em> made of concatenated q-arrows (component q-arrows). In general, the more connections one considers together, the more the
                        actual repertoire will take shape and differ from the uniform (potential) distribution.
                     </p>
                     <p id="p-50">Finally, consider the joint contribution of all connections of the complex (<a id="xref-fig-5-5" class="xref-fig" href="#F5">Fig. 5B</a>). As was discussed above, all connections together specify the actual repertoire of the whole. This is the point where all
                        q-edges converge. Together, these q-edges in Q delimit a <em>quale</em>, that is, a <em>shape</em> in Q, a kind of 2<sup>n</sup>-dimensional
 solid (technically, in more than three dimensions, the “body” of a 
polytope). The bottom of the quale is the
                        maximum entropy distribution, its edges are 
q-edges made of concatenated q-arrows, and its top is the actual 
repertoire of
                        the complex as a whole. The shape of this solid 
(polytope) is specified by all informational relationships that are 
generated
                        within the complex by the interactions among its
 elements (the effective information matrix; <a id="xref-ref-65-13" class="xref-bibr" href="#ref-65">Tononi, 2004</a>).<sup><a id="xref-ref-7-1" class="xref-bibr" href="#ref-7">7</a></sup> Note that the same complex of elements, endowed with the same mechanism, will typically generate a different quale or shape
                        in Q depending on the particular state it is in.
                     </p>
                     <p id="p-51">It is worth considering briefly a few relevant properties of informational relationships or q-arrows. First, informational
                        relationships are context-dependent (<a id="xref-fig-6-1" class="xref-fig" href="#F6">Fig. 6</a>), in the following sense. A <em>context</em>
 can be any point in Q corresponding to the actual repertoire generated 
by a particular subset of connections. It can be shown
                        that the q-arrow generated by considering the 
effects of an additional connection (how it further sharpens the actual 
repertoire)
                        can change in both magnitude and direction 
depending on the context in which it is considered. In <a id="xref-fig-6-2" class="xref-fig" href="#F6">Figure 6</a>,
 when considered in isolation (null context), the connection “r” between
 elements 4 and 3 generates a short q-arrow (0.18
                        bits) pointing in a certain direction. When 
considered in the full context provided by all other connections (not-r 
or ¬r),
                        the same connection “r” generates a longer 
q-arrow (1 bit) pointing in a different direction.
                     </p>
                     <div id="F6" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F6.expansion.html"><img alt="Figure 6." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F6.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F6.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F6.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 6.</span> 
                           <p id="p-126" class="first-child"><strong>Context and entanglement</strong>.
 (A) Context. The same connection (black arrow between elements 3 and 4)
 considered in two contexts. At the bottom of the
                              quale (null context, corresponding to the 
maximum entropy distribution when no other connections are engaged), the
 connection
                              r generates a q-arrow (called down-set of 
r, or ↓r) corresponding to 0.18 bits of information pointing up-left in 
Q. Near
                              the top of the quale (full context, 
corresponding to the actual distribution specified by all other 
connections except for
                              r, indicated as ¬r), r generates a q-arrow
 (called up-set of non-red, or ↑ ¬r) corresponding to 1 bit of 
information pointing
                              up-right in Q. (B) Entanglement. Left: the
 q-arrow generated by the connection “r” and the q-arrow generated by 
the complementary
                              connections “¬ r” at the bottom of the 
quale (null context). Right: The product of the two q-arrows 
(corresponding to independence
                              between the informational relationships 
specified by the two sets of connections) would be a point corresponding
 to the vertex
                              of the dotted parallelogram opposite to 
the bottom. However, “r” and “¬r” jointly specify the actual 
distribution corresponding
                              to the top of the quale (black triangle). 
The distance between the probability distribution in Q specified jointly
 by two
                              sets of connections and their product 
distribution (zigzag arrow) is the entanglement between the two 
corresponding q-arrows
                              (how much the composite q-arrow specifies 
above and beyond its component q-arrows).
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-52">Another property is how removing or adding a set of connections folds or unfolds a quale. The portion of the quale that is
                        generated by a set of connections r (acting in all contexts) is called a <em>q-fold</em>.
 If we remove connection r from the system, all the q-arrows generated 
by that connection, in all possible contexts, vanish,
                        so the shape of the quale “folds” along the 
q-fold specified by that connection. Conversely, when the connection is 
added
                        to a system, the shape of the quale unfolds.
                     </p>
                     <p id="p-53">Another important property of q-arrows is <em>entanglement</em>
 (γ, Balduzzi and Tononi, unpubl.). A q-arrow is entangled (γ &gt; 0) if
 the underlying connections considered together generate
                        information above and beyond the information 
they generate separately (note the analogy with Φ). Thus, entanglement 
characterizes
                        informational relationships (q-arrows) that are 
more than the sum of their component relationships (component q-arrows, <a id="xref-fig-6-3" class="xref-fig" href="#F6">Fig. 6B</a>),
 just like Φ characterizes systems that are more than the sum of their 
parts. Geometrically, entanglement “warps” the shape
                        of the quale away from a simple hypercube (where
 q-arrows are orthogonal to each other). Entanglement has several 
relevant
                        consequences (Balduzzi and Tononi, unpubl.). For
 example, an entangled q-arrow can be said to specify a <em>concept</em>, in that it groups together certain states of affairs in a way that cannot be decomposed into the mere sum of simpler groupings
                        (see also <a id="xref-ref-46-1" class="xref-bibr" href="#ref-46">Feldman, 2003</a>). Moreover, just as Φ can be used to identify complexes, entanglement γ can be used to identify <em>modes</em>. By analogy with complexes, <em>modes</em>
 are sets of q-arrows that are more densely entangled than surrounding 
q-arrows: they can be considered as clusters of informational
                        relationships constituting distinctive 
“sub-shapes” in Q (see <a id="xref-fig-8-1" class="xref-fig" href="#F8">Fig. 8</a>). By analogy with a main complex, an <em>elementary mode</em> is such that its component q-arrows have strictly lower γ. As will be briefly discussed below, modes play an important role
                        in understanding the structure of experience.
                     </p>
                  </div>
                  <div id="sec-12" class="subsection">
                     <h3>Some properties of qualia space</h3>
                     <p id="p-54">What is the relevance of these 
constructs to understanding the quality of consciousness? It is not easy
 to become familiar
                        with a complicated multidimensional space nearly
 impossible to draw, so it may be useful to resort to some metaphors. I 
have
                        argued that the set of informational 
relationships in Q generated by the mechanisms of a complex in a given 
state (q-arrows
                        between repertoires) specify a shape in Q (a 
quale). Perhaps the most important notion emerging from this approach is
 that
                        <em>an experience is a shape in Q</em>. According to the IIT, <em>this shape completely and univocally</em><sup><a id="xref-ref-8-1" class="xref-bibr" href="#ref-8">8</a></sup> <em>specifies the quality of experience</em>.
                     </p>
                     <p id="p-55">It follows that different experiences 
are, literally, different shapes in Q. For example, when the same system
 is in a different
                        state (firing pattern), it will typically 
generate a different shape or quale (even for the same value of Φ). 
Importantly,
                        if an element turns on, it generates information
 and meaning not by signifying something (say “red”), which in isolation
 it
                        cannot, but by changing the shape of the quale. 
Moreover, experiences are similar if their shape is similar, and 
different
                        to the extent that their shapes are different. 
This means that phenomenological similarities and differences can in 
principle
                        be quantified as similarities and differences 
between shapes. The set of all shapes generated by the same system in 
different
                        states provides a geometrical depiction of all 
its possible experiences.<sup><a id="xref-ref-9-1" class="xref-bibr" href="#ref-9">9</a></sup></p>
                     <p id="p-56">Note that a quale can only be 
specified by a mechanism and a particular state—it does not make sense 
to ask about the quale
                        generated by a mechanism in isolation, or by a 
state (firing pattern) in isolation. A consequence is that two different
 systems
                        in the same state can generate two different 
experiences (<em>i.e</em>., two different shapes). As an extreme example, a system that was to copy one by one the state of the neurons in a human
                        brain, but had no internal connections of its own, would generate no consciousness and no quale (<a id="xref-ref-65-14" class="xref-bibr" href="#ref-65">Tononi, 2004</a>; <a id="xref-ref-36-8" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
                     </p>
                     <p id="p-57">By the same token, it is possible that two different systems generate the same experience (<em>i.e</em>.,
 the same shape). For example, consider again the photodiode, whose 
mechanism determines that if the current in the sensor
                        exceeds a threshold, the detector turns on. This
 simple causal interaction is all there is, and when the photodiode 
turns
                        on it merely specifies an actual repertoire 
where states (00,01,10,11) have, respectively, probability 
(0,0,1/2,1/2). This
                        corresponds in Q to a single q-arrow, one bit 
long, going from the potential, maximum entropy repertoire 
(1/4,1/4,1/4,1/4)
                        to (0,0,1/2,1/2). Now imagine the light sensor 
is substituted by a temperature sensor with the same threshold and 
dynamic
                        range—we have a thermistor rather than a 
photodiode. Although the physical device has changed, according to the 
IIT the experience,
                        minimal as it is, has to be the same, since the 
informational relationship that is generated by the two devices is 
identical.
                        Similarly, an AND gate when silent and an OR 
gate when firing also generate the same shape in Q, and therefore must 
generate
                        the same minimal experience (it can be shown 
that the two shapes are isomorphic, that is, have the same symmetries; 
Balduzzi
                        and Tononi, unpubl.). In other words, different 
“physical” systems (possibly in different states) generate the same 
experience
                        if the shape of the informational relationships 
they specify is the same. On the other hand, more complex networks of 
causal
                        interactions are likely to create highly 
idiosyncratic shapes, so systems of high Φ are unlikely to generate 
exactly identical
                        experiences.
                     </p>
                     <p id="p-58">If experience is integrated 
information, it follows that only the informational relationships within
 a complex (those that
                        give the quale its shape) contribute to 
experience. Conversely, the informational relationships that exist 
outside the main
                        complex—for example, those involving sensory 
afferents or cortico-subcortical loops implementing informationally 
insulated
                        subroutines—do not make it into the quale, and 
therefore do not contribute either to the quantity or to the quality of 
consciousness.
                     </p>
                     <p id="p-59">Note also that informational 
relationships, and thus the shape of the quale, are specified both by 
the elements that are firing
                        and by those that are not. This is natural 
considering that an element that does not fire will typically rule out 
some previous
                        states of affairs (those that would have made it
 fire), and thereby it will contribute to specifying the actual 
repertoire.
                        Indeed, many silent elements can rule out, in 
combination, a vast number of previous states and thus be highly 
informative.
                        From a neurophysiological point of view, such a 
corollary may lead to counterintuitive predictions. For example, take 
elements
                        (neurons) within the main complex that happen to
 be silent when one is having a particular experience. If one were to 
temporarily
                        disable these neurons (<em>e.g</em>., make them <em>incapable</em> of firing), the prediction is that, though the system state (firing pattern) would remain the same, the quantity and quality
                        of experience would change (<a id="xref-ref-65-15" class="xref-bibr" href="#ref-65">Tononi, 2004</a>; <a id="xref-ref-36-9" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
                     </p>
                     <p id="p-60">It is important to see what Φ corresponds to in this representation (<a id="xref-fig-7-1" class="xref-fig" href="#F7">Fig. 7A</a>). The minimum information partition (MIP) is just another point in Q: the one specified by the connections <em>within</em> the minimal parts only, leaving out the contribution of the connections <em>among</em>
 the parts. This point is the actual repertoire corresponding to the 
product of the actual repertoires of the parts taken
                        independently. Φ corresponds then to an arrow 
linking this point to the top of the solid. In this view, the q-edges 
leading
                        to the minimum information bipartition provide 
the natural “base” upon which the solid rests—the informational 
relationships
                        generated <em>within</em> the parts upon which are built the informational relationships <em>among</em>
 the parts. The Φ-arrow can then be thought of as the height of the 
solid—or rather, to employ a metaphor, as the highest
                        pole holding up a tent. For example, if Φ is 
zero (say a system decomposes into two independent complexes as in <a id="xref-fig-7-2" class="xref-fig" href="#F7">Fig. 7B</a>),
 the tent corresponding to the system is flat—it has no shape—since the 
actual repertoire of the system collapses onto its
                        base (MIP). This is precisely what it means when
 Φ = 0. Conversely, the higher the Φ value of a complex (the higher the 
tent
                        or solid), the more “breathing room” there is 
for the various informational relationships within the complex (the 
edges of
                        the solid or the seams of the tent) to express 
themselves.
                     </p>
                     <div id="F7" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F7.expansion.html"><img alt="Figure 7." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F7.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F7.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F7.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 7.</span> 
                           <p id="p-127" class="first-child"><strong>The tent analogy</strong>. (A) The system of <a id="xref-fig-2-6" class="xref-fig" href="#F2">Fig. 2A</a>′ / <a id="xref-fig-5-7" class="xref-fig" href="#F5">Fig. 5</a>. (B) The q-edges converging on the minimum information partition of the system (MIP) form the natural base on which the complex
                              rests, depicted as a “tent.” The informational relationships <em>among</em> the parts are built on top of the informational relationships generated independently <em>within</em>
 the minimal parts. From this perspective the Φ q-arrow (in black) is 
simply the tent pole holding the quale up above its
                              base; the length (divergence) of the pole 
expresses the breathing room in the system. The thick gray q-arrow 
represents the
                              information generated by the entire 
system. (C) The system of <a id="xref-fig-2-7" class="xref-fig" href="#F2">Fig. 2A</a>. The quale (not) generated by the two photodiodes considered as a single system. As shown in <a id="xref-fig-2-8" class="xref-fig" href="#F2">Fig. 2A</a>,
 the system reduces to two independent parts, so it does not exist as a 
single entity. (D) Note that in this case the quale
                              reduces to the MIP: the “tent” collapses 
onto its base, so there is no breathing room for informational 
relationships within
                              the system. The quale generated by each 
part considered in isolation does exist, corresponding to an identical 
q-arrow for
                              each couple.
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-61">In summary, and not very rigorously, 
the generation of an experience can be thought of as the erection of a 
tent with a very
                        complex structure: the edges are the tension 
lines generated by each subset of connections (the respective q-arrow or
 informational
                        relationship). The tent literally takes shape 
when the connections are engaged and specify actual repertoires. Perhaps
 an
                        even more daring metaphor would be the 
following: whenever the mechanisms of a complex unfold and specify 
informational relationships,
                        the flower of experience blooms.
                     </p>
                  </div>
                  <div id="sec-13" class="subsection">
                     <h3>From phenomenology to geometry</h3>
                     <p id="p-62">The notions just sketched aim at 
providing a framework for translating the seemingly ineffable 
qualitative properties of phenomenology
                        into the language of mathematics, specifically, 
the language of informational relationships (q-arrows) in Q. Ideally, 
when
                        sufficiently developed, such language should 
permit the geometric characterization of phenomenological properties 
generated
                        by the human brain. In principle, it should also
 allow us to characterize the phenomenology of other systems. After all,
 in
                        this framework the experience of a bat 
echo-locating in a cave is just another shape in Q and, at least in 
principle, shapes
                        can be compared objectively.
                     </p>
                     <p id="p-63">At present, due to the combinatorial 
problems posed by deriving the shape of the quale produced by systems of
 just a few elements,
                        and to the additional difficulties posed by 
representing such high-dimensional objects, the best one can hope for is
 to show
                        that the language of Q can capture, in 
principle, some of the basic distinctions that can be made in our own 
phenomenology,
                        as well as some key neuropsychological 
observations (Balduzzi and Tononi, unpubl.). A short list includes the 
following:
                     </p>
                     <p id="p-64">(i) Experience is divided into 
modalities, like the classic senses of sight, hearing, touch, smell, and
 taste (and several
                        others), as well as submodalities, like visual 
color and visual shape. What do these broad distinctions correspond to 
in Q?
                        According to the IIT, modalities are sets of 
densely entangled q-arrows (<em>modes</em>) that form distinct <em>sub-shapes</em> in the quale; submodalities are subsets of even more densely entangled q-arrows (sub-modes) within a larger mode, thus forming
                        distinct sub-sub-shapes (<a id="xref-fig-8-2" class="xref-fig" href="#F8">Fig. 8</a>).
 As a two-dimensional analog, imagine a given multimodal experience as 
the shape of the three-continent complex constituted
                        by Europe, Asia, and Africa. The three 
continents are distinct sub-shapes, yet they are all part of the same 
landmass, just
                        as modalities are parts of the same 
consciousness. Moreover, within each continent there are peninsulas 
(sub-sub-shapes),
                        like Italy in Europe, just as there are 
submodalities within modalities.
                     </p>
                     <div id="F8" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F8.expansion.html"><img alt="Figure 8." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F8.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F8.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F8.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 8.</span> 
                           <p id="p-128" class="first-child"><strong>Modes</strong>.
 Schematic depiction of modes and sub-modes. A mode, indicated by a 
polygon within the quale (light gray with black border),
                              is a set of q-arrows that are more densely
 entangled than surrounding q-arrows, and can be considered as clusters 
of informational
                              relationships constituting distinctive 
“sub-shapes” in Q. Two different modes could correspond, for example, to
 the modalities
                              of sight and sound. A sub-mode within a 
mode is a set of q-arrows that is even more densely entangled (a 
sub-sub-shape in
                              Q). Color and form could correspond to two
 sub-modes within the visual mode. The thin black polygon represents an 
elementary
                              mode, which does not contain more densely 
entangled q-arrows. Elementary modes could correspond to experiential 
qualities
                              that cannot be further decomposed, such as
 the color “red” (qualia in the narrow sense.)
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-65">(ii) Some experiences appear to be 
“elementary,” in that they cannot be further decomposed. A typical 
example is what philosophers
                        call a “quale” in the narrow sense—say a pure 
color like red, or a pain, or an itch: it is difficult, if not 
impossible, to
                        identify any further phenomenological structure 
within the experience of red. According to the IIT, such elementary 
experiences
                        correspond to sub-modes that do not contain any 
more densely entangled sub-sub-modes (<em>elementary modes</em>, <a id="xref-fig-8-3" class="xref-fig" href="#F8">Fig. 8</a>).
                     </p>
                     <p id="p-66">(iii) Some experiences are homogeneous
 and others are composite: for example, a full-field experience of blue,
 as when watching
                        a cloudless sky, compared to that of a busy 
market street. In Q, homogeneous experiences translate to a single 
homogeneous
                        shape, and composite ones into a composite shape
 with many distinguishable sub-shapes (modes and sub-modes).
                     </p>
                     <p id="p-67">(iv) Some experiences are 
hierarchically organized. Take seeing a face: we see at once that as a 
whole it is somebody's face,
                        but we also see that it has parts such as hair, 
eyes, nose, and mouth, and that those are made in turn of specifically 
oriented
                        segments. The subjective experience is 
constructed from informational relationships (q-arrows) that are 
entangled (not reducible
                        to a product of independent components) across 
hierarchical levels. For example, informational relationships 
constituting
                        “face” would be more densely tangled than 
unnatural combinations such as seen in certain Cubist paintings. The 
sub-shape of
                        the quale corresponding to the experience of 
seeing a face is then an overlapping hierarchy of tangled q-arrows, 
embodying
                        relationships within and across levels.
                     </p>
                     <p id="p-68">(v) We recognize intuitively that the 
way we perceive taste, smell, and maybe color, is organized 
phenomenologically in a
                        “categorical” manner, quite different from, say,
 the “topographical” manner in which we perceive space in vision, 
audition,
                        or touch. According to the IIT, these 
hard-to-articulate phenomenological differences correspond to different 
basic sub-shapes
                        in Q, such as 2<sup>n</sup>-dimensional <em>grid-like</em> structures and <em>pyramid-like</em> structures, which emerge naturally from the underlying neuroanatomy.
                     </p>
                     <p id="p-69">(vi) Some experiences are more alike 
than others. Blue is certainly different from red (and irreducible to 
red), but clearly
                        it seems even more different from middle C on 
the oboe. In the IIT framework, in Q colors correspond to different 
sub-shapes
                        of the same kind (say pyramids pointing in 
different directions) and sounds to very different sub-shapes (say 
tetrahedra).
                        In principle, such subjective similarities and 
differences can be investigated by employing objective measures of <em>similarity between shapes</em> (<em>e.g</em>.,
 considering the number and kinds of symmetries involved in specifying 
shapes that are generated in Q by different neuroanatomical
                        circuits).
                     </p>
                     <p id="p-70">(vii) Experiences can be refined 
through learning and changes in connectivity. Suppose one learns to 
distinguish wine from
                        water, then red wines from whites, then 
different varietals. Presumably, underlying this phenomenological 
refinement is a
                        neurobiological refinement: neurons that 
initially were connected indiscriminately to the same afferents become 
more specialized
                        and split into sub-groups with partially 
segregated afferents. This process has a straightforward equivalent in 
Q: the single
                        q-arrow generated initially by those afferents <em>splits</em> into two or more q-arrows pointing in different directions, and the overall sub-shape of the quale is correspondingly refined.
                     </p>
                     <p id="p-71">(viii) Qualia in the narrow sense (elementary modes) exist “at the top of experience” and not at its bottom. Consider the
                        experience of seeing a pure color, such as red. The evidence suggests that the “neural correlate” (<a id="xref-ref-42-1" class="xref-bibr" href="#ref-42">Crick and Koch, 2003</a>)
 of color, including red, is probably a set of neurons and connections 
in the fusiform gyrus, maybe in area V8 (ideally,
                        neurons in this area are activated whenever a 
subject sees red and not otherwise, if stimulated trigger the experience
 of
                        red, and if lesioned abolish the capacity to see
 red). Certain achromatopsic subjects with dysfunctions in this general 
area
                        seem to lack the feeling of what it is like to 
see color, its “coloredness,” including the “redness” of red. They 
cannot experience,
                        imagine, remember, or even dream of color, 
though they may talk about it, just as we could talk about echolocation,
 from a
                        third-person perspective (<a id="xref-ref-70-1" class="xref-bibr" href="#ref-70">van Zandvoort <em>et al</em>., 2007</a>).
 Contrast such subjects, who are otherwise perfectly conscious, with 
vegetative patients, who are for all intents and purposes
                        unconscious. Some of these patients may show 
behavioral and neurophysiological evidence for residual function in an 
isolated
                        brain area (<a id="xref-ref-59-2" class="xref-bibr" href="#ref-59">Posner and Plum, 2007</a>). Yet it seems highly unlikely that a vegetative patient with residual activity exclusively in V8 should enjoy the vivid
                        perceptions of color just as we do, while being otherwise unconscious.
                     </p>
                     <p id="p-72">The IIT provides a straightforward account for this difference. To see how, consider again <a id="xref-fig-6-4" class="xref-fig" href="#F6">Figure 6A</a>:
 call “r” the connections targeting the “red” neurons in V8 that confer 
them their selectivity, and non-r (¬r) all the other
                        connections within the main corticothalamic 
complex. Adding r in isolation at the bottom of Q (null context) yields a
 small
                        q-arrow (called the <em>down-set of red</em> or 
↓r) that points in a direction representing how r by itself shapes the 
maximum entropy distribution into an actual repertoire.
                        Schematically, this situation resembles that of a
 vegetative patient with V8 and its afferents intact but the rest of the
                        corticothalamic system destroyed. The shape of 
the experience or quale reduces to this q-arrow, so its quantity is 
minimal
                        (Φ for this q-arrow is obviously low) and its 
quality minimally specified: as we have seen with the photodiode, r by 
itself
                        cannot specify whether the experience is a color
 rather than something else such as a shape, whether it is visual or 
not,
                        sensory or not, and so on.
                     </p>
                     <p id="p-73">By contrast, subtract r from the set of all connections, so one is left with ¬r. This “lesion” collapses the q-fold specified
                        by r in all contexts, including the q-arrow, called the <em>up-set of non-red</em> (↑¬r), which starts from the full context provided by all other connections ¬r and reaches the top of the quale.<sup><a id="xref-ref-10-1" class="xref-bibr" href="#ref-10">10</a></sup>
 This q-arrow will typically be much longer and point in a different 
direction than the q-arrow generated by r at the bottom
                        of the quale. This is because, the fuller the 
context, the more r can shape the actual repertoire. Schematically, 
removing
                        r from the top resembles the situation of an 
achromatopsic patient with a selective lesion of V8: the bulk of the 
experience
                        or quale remains intact (Φ remains high), but a 
noticeable feature of its shape collapses (the upset of non-red). 
According
                        to the IIT, the feature of the shape of the 
quale specified by “the upset of non-red” captures the very quality or 
“redness”
                        of red.<sup><a id="xref-ref-11-1" class="xref-bibr" href="#ref-11">11</a></sup></p>
                     <p id="p-74">It is worth remarking that the last example also shows why specific qualities of consciousness, such as <em>the “redness” of red, while generated by a local mechanism, cannot be reduced to it</em>.
 If an achromatopsic subject without the r connections lacks precisely 
the “redness” of red, whereas a vegetative patient
                        with just the r connections is essentially 
unconscious, then the redness of red cannot map directly to the 
mechanism implemented
                        by the r connections. However, the redness of 
red can map nicely onto the informational relationships specified by r, 
as these
                        change dramatically between the null context 
(vegetative patient) and the full context (achromatopsic subject).
                     </p>
                  </div>
               </div>
               <div class="section" id="sec-14">
                  <div class="section-nav"><a href="#sec-10" title="The Quality of Consciousness: Characterizing Informational Relationships" class="prev-section-link"><span>Previous Section</span></a><a href="#ack-1" title="Acknowledgments" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>A Provisional Manifesto</h2>
                  <p id="p-75">To recapitulate, the IIT claims that the 
quantity of consciousness is given by the integrated information (Φ) 
generated by
                     a complex of interacting elements, and its quality 
by the shape in Q specified by their informational relationships. As I
                     have tried to indicate here, this theoretical 
framework can account for basic neurobiological and neuropsychological 
observations.
                     Moreover, the same framework can be extended to 
begin translating phenomenology into the language of mathematics.
                  </p>
                  <p id="p-76">At present, the very notion of a 
theoretical approach to consciousness may appear far-fetched, yet the 
nature of the problems
                     posed by a science of consciousness requires a 
combination of experiment and theory: one could say that theories 
without experiments
                     are lame, but experiments without theories are 
blind. For instance, only a theoretical framework can go beyond a 
provisional
                     list of candidate mechanisms or brain areas and 
provide a principled explanation of why they may be relevant. Also, only
 a
                     theory can account, in a coherent manner, for key 
but puzzling facts about consciousness and the brain, such as the 
association
                     of consciousness with the corticothalamic but not 
the cerebellar system, the “unconscious” functioning of many 
cortico-subcortical
                     circuits, or the fading of consciousness during 
certain stages of sleep or epilepsy.
                  </p>
                  <p id="p-77">A theory should also generate relevant 
corollaries. For example, the IIT predicts that consciousness depends 
exclusively on
                     the ability of a system to generate integrated 
information: whether or not the system is interacting with the 
environment
                     on the sensory and motor side, it deploys language,
 capacity for reflection, attention, episodic memory, a sense of space,
                     of the body, and of the self. These are obviously 
important functions of complex brains and help shape its connectivity. 
Nevertheless,
                     contrary to some common intuitions, but consistent 
with the overall neurological evidence, none of these functions seems 
absolutely
                     necessary for the generation of consciousness “here
 and now” (<a id="xref-ref-67-1" class="xref-bibr" href="#ref-67">Tononi and Laureys, 2008</a>).
                  </p>
                  <p id="p-78">Finally, a theory should be able to help 
in “difficult” cases that challenge our intuition or our standard ways 
to assess
                     consciousness. For instance, the IIT says that the 
presence and extent of consciousness can be determined, in principle, 
also
                     in cases in which we have no verbal report, such as
 infants or animals, or in neurological conditions such as minimally 
conscious
                     states, akinetic mutism, psychomotor seizures, and 
sleepwalking. In practice, of course, measuring Φ accurately in such 
systems
                     will not be easy, but approximations and informed 
estimates are certainly conceivable. Whether these and other predictions
                     turn out to be compatible with future clinical and 
experimental evidence, a coherent theoretical framework should at least
                     help to systematize a number of neuropsychological 
and neurobiological results that might otherwise seem disparate (<a id="xref-ref-32-1" class="xref-bibr" href="#ref-32">Albus <em>et al</em>., 2007</a>).
                  </p>
                  <p id="p-79">In the remaining part of this article, I briefly consider some implications of the IIT for the place of experience in our
                     view of the world.
                  </p>
                  <div id="sec-15" class="subsection">
                     <h3>Consciousness as a fundamental property</h3>
                     <p id="p-80">According to the IIT, consciousness is
 one and the same thing as integrated information. This identity, which 
is predicated
                        on the phenomenological thought experiments at 
the origin of the IIT, has ontological consequences. Consciousness 
exists beyond
                        any doubt (indeed, it is the only thing whose 
existence is beyond doubt). If consciousness is integrated information, 
then
                        integrated information exists. Moreover, 
according to the IIT, it exists as a fundamental quantity—as fundamental
 as mass,
                        charge, or energy. As long as there is a 
functional mechanism in a certain state, it must exist <em>ipso facto</em> as integrated information; specifically, it exists as an experience of a certain quality (the shape of the quale it generates)
                        and quantity (its “height” Φ).<sup><a id="xref-ref-12-1" class="xref-bibr" href="#ref-12">12</a></sup></p>
                     <p id="p-81">If one accepts these premises, a 
useful way of thinking about consciousness as a fundamental property is 
as follows. We are
                        by now used to considering the universe as a 
vast empty space that contains enormous conglomerations of mass, charge,
 and
                        energy—giant bright entities (where brightness 
reflects energy or mass) from planets to stars to galaxies. In this view
 (that
                        is, in terms of mass, charge, or energy), each 
of us constitutes an extremely small, dim portion of what exists—indeed,
 hardly
                        more than a speck of dust.
                     </p>
                     <p id="p-82">However, if consciousness (<em>i.e</em>.,
 integrated information) exists as a fundamental property, an equally 
valid view of the universe is this: a vast empty space
                        that contains mostly nothing, and occasionally 
just specks of integrated information (Φ)—mere dust, indeed—even there 
where
                        the mass-charge–energy perspective reveals huge 
conglomerates. On the other hand, one small corner of the known universe
 contains
                        a remarkable concentration of extremely bright 
entities (where brightness reflects high Φ), orders of magnitude 
brighter than
                        anything around them. Each bright “Φ-star” is 
the main complex of an individual human being (and most likely, of 
individual
                        animals).<sup><a id="xref-ref-13-1" class="xref-bibr" href="#ref-13">13</a></sup>
 I argue that such Φ-centric view is at least as valid as that of a 
universe dominated by mass, charge, and energy. In fact,
                        it may be more valid, since to be highly 
conscious (to have high Φ) implies that there is something it is like to
 be you,
                        whereas if you just have high mass, charge, or 
energy, there may be little or nothing it is like to be you. From this 
standpoint,
                        it would seem that entities with high Φ <em>exist</em> in a stronger sense than entities of high mass.
                     </p>
                     <p id="p-83">Intriguingly, it has been suggested, from a different perspective, that information may be, in an ontological sense, prior
                        to conventional physical properties (the it from bit perspective; <a id="xref-ref-71-1" class="xref-bibr" href="#ref-71">Wheeler and Ford, 1998</a>). This may well be true but, according to the IIT, only if one substitutes “integrated information” for information.<sup><a id="xref-ref-14-1" class="xref-bibr" href="#ref-14">14</a></sup>
 Information that is not integrated, I have argued, is not associated 
with experience, and thus does not really exist as such:
                        it can only be given a vicarious existence by a 
conscious observer who exploits it to achieve certain discriminations 
within
                        his main complex. Indeed, the same “information”
 may produce very different consequences in different observers, so it 
only
                        exists through them but not in and of itself.
                     </p>
                  </div>
                  <div id="sec-16" class="subsection">
                     <h3>Consciousness as an intrinsic property</h3>
                     <p id="p-84">Consciousness, as a fundamental property, is also an <em>intrinsic</em>
 property. This simply means that a complex generating integrated 
information is conscious in a certain way regardless of
                        any extrinsic perspective. This point is 
especially relevant if we consider how difficult it is to measure the 
quantity of
                        integrated information, not to mention the shape
 of a quale, for any realistic system. If we want to know what are the 
borders
                        of a certain complex, the amount of integrated 
information it generates, the set of informational relationships it 
specifies,
                        and the spatio-temporal grain at which Φ is 
highest (see below), we need to perform a prohibitively large set of 
computations.
                        One would need to perturb a system in all 
possible ways and use Bayes’ rule to keep track of the probabilities of 
the previous
                        states given the current output, and then 
calculate the relative entropy between the potential and the actual 
distributions.
                        Moreover, this must be done for all possible 
subsets of a system (to find complexes) and for all combinations of 
connections
                        (to obtain the shape of each quale). Finally, 
the calculations must be repeated at multiple spatial and temporal 
scales to
                        determine what is the optimal grain size, in 
space and time, for generating integrated information (see below). It 
goes without
                        saying that these calculations are presently 
unfeasible for anything but the smallest systems. It also goes without 
saying
                        that a complex itself cannot and need not go 
through such calculations: it is intrinsically conscious in this or that
 way.
                        In fact, it needs as little to “calculate” all 
the relevant probability distributions to generate consciousness and 
specify
                        its quality, as a body of a certain mass needs 
to “calculate” how much gravitational mass it has in order to attract 
other
                        bodies.
                     </p>
                     <p id="p-85">Another way to express this aspect of integrated information is to say that consciousness can be characterized extrinsically
                        as a disposition or <em>potentiality</em> –in this case as the potential discriminations that a complex can do on its possible states, through all combinations of
                        its mechanisms, yet from an intrinsic perspective it is undeniably <em>actual</em>.
 While this may sound strange, fundamental quantities associated with 
physical systems can also be characterized as dispositions
                        or potentialities, yet have actual effects. For 
example, mass can be characterized as a potentiality—say the resistance 
that
                        a body would offer to acceleration by a 
force—yet it exerts undeniably actual effects, such as actually 
attracting other masses
                        if these turn out to be there. Similarly, a 
mechanism's potential for integrated information becomes actual by 
virtue of the
                        fact that the mechanism is actually in a 
particular state. Paraphrasing E. M. Forster, one could express this 
fact as follows:
                        <em>How do I know what I am till I see what I do?</em></p>
                  </div>
                  <div id="sec-17" class="subsection">
                     <h3>Being and describing</h3>
                     <p id="p-86">According to the IIT, a full <em>description</em> of the set of informational relationships generated by a complex at a given time should say all there is to say about the
                        experience it is having at that time: nothing else needs to be added.<sup><a id="xref-ref-19-1" class="xref-bibr" href="#ref-19">17</a></sup> Nevertheless, the IIT also implies that to be conscious—say to have a vivid experience of pure red—one needs to <em>be</em> a complex of high Φ; there is no other way. Obviously, although a full description can provide understanding of what experience
                        is and how it can be generated, it cannot substitute for it: <em>being is not describing</em>.
 This point should be uncontroversial, but it is worth mentioning 
because of a well-known argument against a scientific explanation
                        of consciousness, best exemplified by a thought 
experiment involving Mary, a neuroscientist in the 23rd century (<a id="xref-ref-50-1" class="xref-bibr" href="#ref-50">Jackson, 1986</a>).
 Mary knows everything about the brain processes responsible for color 
vision, but has lived her whole life in a black-and-white
                        room and has never seen any color.<sup><a id="xref-ref-49-2" class="xref-bibr" href="#ref-49">18</a></sup>
 The argument goes that, despite her complete knowledge of color vision,
 Mary does not know what it is like to experience
                        a color: it follows that there is some knowledge
 about conscious experience that cannot be deduced from knowledge about 
brain
                        processes. The argument loses its strength the 
moment one realizes that consciousness is a way of being rather than a 
way
                        of knowing. According to the IIT, being implies 
“knowing” from the inside, in the sense of generating information about 
one's
                        previous state. Describing, instead, implies 
“knowing” from the outside. This conclusion is in no way surprising: 
just consider
                        that though we understand quite well how energy 
is generated by atomic fission, unless atomic fission occurs, no energy 
is
                        generated—no amount of description will 
substitute.
                     </p>
                  </div>
                  <div id="sec-18" class="subsection">
                     <h3>Observer pitfalls: minimal elements and minimal interactions</h3>
                     <p id="p-87">Because integrated information is an intrinsic property, it is especially important that one avoid the observer fallacy in
                        estimating how much of it is generated by a system. Consider the system in <a id="xref-fig-9-1" class="xref-fig" href="#F9">Figure 9A</a> (top). An observer might assume that the system is made up of two units, each with a repertoire of 2<sup><em>n</em></sup> states. If the lower unit copies the output of the upper unit, then this two-unit system generates <em>n</em> bits of integrated information—it would seem trivial to implement systems with arbitrarily large values of Φ. But how is
                        the system really built? <a id="xref-fig-9-2" class="xref-fig" href="#F9">Figure 9A</a> (bottom) shows a possible architecture: each “unit” is actually not a unit at all, but it contains <em>n</em> binary elements. Each upper element is then connected to the corresponding lower element. Seen this way, it becomes obvious
                        that the system is not a complex generating <em>n</em> bits of integrated information, but rather a collection of independent couples (or photodiodes) each generating 1 bit of
                        integrated information, just as in <a id="xref-fig-2-3" class="xref-fig" href="#F2">Figure 2</a>.
 Note that, if we try to “integrate” the couples by adding horizontal 
connections between elements, we reduce the available
                        information. Thus, integrated information has to
 be evaluated from the perspective of the system itself, starting from 
its
                        elementary, indivisible components (see also the
 next point), and not by arbitrarily imposing “units” from the 
perspective
                        of an observer.
                     </p>
                     <div id="F9" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F9.expansion.html"><img alt="Figure 9." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F9.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F9.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F9.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 9.</span> 
                           <p id="p-129" class="first-child"><strong>Analyzing systems in terms of elementary components and operations</strong>. (A) and (B) show systems that on the surface appear to generate a large amount of integrated information. The units in (A)
                              have a repertoire of 2<sup><em>n</em></sup> outputs, with the bottom unit copying the top. Integrated information is <em>n</em> bits. By analyzing the internal structure of the system in (A′) we find <em>n</em> disjoint couples, each integrating 1 bit of information; the entire system, however, is not integrated. (B) shows a system
                              of binary units. The top unit receives inputs from eight other units and performs an <em>AND</em>-gate
 like operation, firing if and only if all eight inputs are spikes. 
Increasing the number of inputs appears to easily
                              increase Φ without limit. (B′) examines a 
possible implementation of the internal architecture of the top unit 
using binary
                              <em>AND</em>-gates. The architecture has a bottleneck, shown as the MIP line, so that Φ = 1 bit regardless of the number of input units.
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-88"><a id="xref-fig-9-3" class="xref-fig" href="#F9">Figure 9B</a> (top) illustrates a similar problem with respect to elementary operations. The system contains <em>n</em>+1 binary components, with a single component receiving inputs from the other <em>n</em>; the component fires if all <em>n</em> inputs are active. The minimum information partition is the total partition P = {X} and Φ = <em>n</em> bits when the top component is firing, since it uniquely specifies the prior state of the other <em>n</em> components. Increasing the number of inputs feeding into the top component while maintaining the same rule—fire if and only
                        if all inputs are active—seems to provide a method for constructing systems with high Φ<sup><a id="xref-ref-46-2" class="xref-bibr" href="#ref-46">15</a></sup>
 using binary components and a basic architecture that is certainly easy
 to describe. The difficulty once again lies in physically
                        implementing a component that processes <em>n</em> inputs at a single point in space and at a single instant in time for large <em>n</em>. <a id="xref-fig-9-4" class="xref-fig" href="#F9">Figure 9B</a>
 (bottom) shows a possible internal architecture of the component, 
constructed using a hierarchy of logical AND-gates. When
                        analyzed at this level, it is apparent that the 
system generates 1 bit of integrated information regardless of the 
number
                        of inputs that feed into the top component, 
since the bipartition framed by the dashed cut forms a bottleneck. As in
 the previous
                        example, integrated information has to be 
evaluated from the perspective of the system itself, based on the 
elementary causal
                        interactions its elements can perform, and not 
by arbitrarily imposing “rules” from the perspective of an observer with
 no
                        regard to their actual implementation. It is 
well known that all computations (or Boolean functions) can be performed
 by elementary
                        logical gates such as NOR or NAND gates acting 
on elementary binary elements. In principle, then, a system should be 
decomposed
                        into minimal elements and minimal 
interactions—as elementary as they come in terms of physical 
implementation—before any pronouncement
                        is made on its capacity to generate integrated 
information and thereby consciousness.<sup><a id="xref-ref-18-1" class="xref-bibr" href="#ref-18">16</a></sup></p>
                  </div>
                  <div id="sec-19" class="subsection">
                     <h3>Consciousness and the spatiotemporal grain of reality</h3>
                     <p id="p-89">An outstanding issue is finding a 
principled way to determine the proper spatial and temporal scale to 
measure informational
                        relationships and integrated information. What 
are the elements upon which probability distributions of states are to 
be evaluated?
                        For example, are they minicolumns or neurons? 
And what about molecules, atoms, or subatomic particles? Similarly, what
 is
                        the “clock” to use to identify system states? 
Does it run in seconds, hundreds of milliseconds, milliseconds, or 
microseconds?
                     </p>
                     <p id="p-90">Properly addressing this issue requires a comprehensive theoretical approach to the relationship between integrated information,
                        emergence, and memory (Balduzzi and Tononi, unpubl.). The working hypothesis is as follows (<a id="xref-ref-65-16" class="xref-bibr" href="#ref-65">Tononi, 2004</a>):
 In general, for any system, integrated information is generated at 
multiple spatiotemporal scales. In particular, however,
                        there will often be a privileged spatiotemporal 
“grain size” at which a given system forms a complex of highest Φ—the 
spatiotemporal
                        scale at which it “exists” the most in terms of 
integrated information, and therefore of consciousness.
                     </p>
                     <p id="p-91">For example, while in the brain there 
are many more atoms than neurons, it is likely that complexes at the 
spatial scale of
                        atoms are exceedingly small, or at any rate that
 they cannot maintain both functional specialization and long-range 
integration,
                        thus yielding low values of Φ. At the other 
extreme, the spatial scale of cortical areas is almost certainly too 
coarse for
                        yielding high values of Φ. Somewhere in between,
 most naturally at the grain size of neurons or minicolumns, the 
neuroanatomical
                        arrangement ensures an ideal mix of functional 
specialization and integration, leading to the formation of a large 
complex
                        of high Φ.
                     </p>
                     <p id="p-92">Similarly, with respect to time, 
neurons would yield zero Φ at the scale of microseconds, since there is 
simply not enough
                        time for engaging their mechanisms. At long time
 scales, say hours, Φ would also be low, as output states would bear 
little
                        relationship to input states. Somewhere in 
between, at a time scale of tens to hundreds of milliseconds, the firing
 pattern
                        of a large complex of neurons should be 
maximally predictive of its previous state, thus yielding high Φ. It is 
not by chance,
                        according to the IIT, that this is both the time
 scale at which experience seems to flow (<a id="xref-ref-35-2" class="xref-bibr" href="#ref-35">Bachmann, 2000</a>) and that at which long-range neuronal interactions occur (<a id="xref-ref-43-2" class="xref-bibr" href="#ref-43">Dehaene <em>et al</em>., 2003</a>; <a id="xref-ref-51-3" class="xref-bibr" href="#ref-51">Koch, 2004</a>).<sup><a id="xref-ref-23-1" class="xref-bibr" href="#ref-23">21</a></sup></p>
                     <p id="p-93">This working hypothesis also suggests 
that the generation of integrated information may set an intrinsic 
framework for both
                        space and time. With respect to time, for 
example, consider a complex generating a certain shape in Q through a 
fast mechanism,
                        and another complex that generates exactly the 
same shape, but through a slower mechanism. It would seem that these two
 complexes
                        should generate exactly the same experience, 
except that time would flow faster in one case and slower in the other. 
Similar
                        considerations may apply to space. Also, 
according to the IIT, what constitutes a “state” of the system is not an
 arbitrary
                        choice from an extrinsic perspective, but rather
 the spatiotemporal grain size at which the system can best generate 
information
                        about its past: <em>what is, is what can make a difference</em>.
                     </p>
                  </div>
                  <div id="sec-20" class="subsection">
                     <h3>Consciousness as a graded quantity</h3>
                     <p id="p-94">The IIT claims that consciousness is 
not an all-or-none property, but is graded: specifically, it increases 
in proportion
                        to a system's repertoire of discriminable 
states. Strictly speaking, then, the IIT implies that even a binary 
photodiode is
                        not completely unconscious, but rather enjoys 
exactly 1 bit of consciousness. Moreover, the photodiode's consciousness
 has
                        a certain quality to it—the simplest possible 
quality—that is captured by a single q-arrow of length 1 bit.<sup><a id="xref-ref-21-1" class="xref-bibr" href="#ref-21">19</a></sup></p>
                     <p id="p-95">How close is this position to 
panpsychism, which holds that everything in the universe has some kind 
of consciousness? Certainly,
                        the IIT implies that many entities, as long as 
they include some functional mechanisms that can make choices between 
alternatives,
                        have some degree of consciousness. Unlike 
traditional panpsychism, however, the IIT does not attribute 
consciousness indiscriminately
                        to all things. For example, if there are no 
interactions, there is no consciousness whatsoever. For the IIT, a 
camera sensor
                        as such is completely unconscious (in fact, it 
does not exist as an entity). Moreover, panpsychism hardly has a solid 
conceptual
                        foundation. The attribution of consciousness to 
all kinds of things is based more on an attempt to avoid dualism than on
 a
                        principled analysis of what consciousness is. 
Similarly, panpsychism offers hardly any guidance as to what would 
determine
                        the amount of consciousness associated with 
different things (such as humans, animals, plants, or rocks), or with 
the same
                        thing at different times (say wakefulness and 
sleep), not to mention that it says nothing about what would determine 
the quality
                        of experience.
                     </p>
                     <p id="p-96">A more relevant issue is the 
following: How can the theory attribute consciousness (albeit minimal) 
to a photodiode, while
                        acknowledging that we “lose” consciousness every
 night when falling into dreamless sleep? After all, the sleeping brain 
likely
                        generates more integrated information than a 
photodiode. Two considerations are in order. First, we have first-hand 
“experience”
                        that consciousness can be graded: falling asleep
 is often a rapid process but, before we are “gone” altogether, we 
occasionally
                        do go through some degree of restriction in the 
field of consciousness, where we are progressively less aware of 
ourselves
                        and the environment. Something similar also 
happens at certain stages of alcohol intoxication. So the level of 
consciousness
                        can indeed change around our typical waking 
baseline, allowing for some gradation.
                     </p>
                     <p id="p-97">Below a certain level of 
consciousness, however, it truly feels as if we fade away completely. 
But is consciousness really
                        annihilated? Is it likely that when we “lose” 
consciousness the amount of integrated information generated by the 
corticothalamic
                        main complex decreases nonlinearly? Computer 
simulations indicate that when the overall activation of corticothalamic
 networks
                        goes below a certain level, there is a sudden 
drop in the average effective information between distant parts of the 
cortex
                        (Tononi, unpubl. obs.). In other words, below a 
certain threshold of activation the corticothalamic system breaks down 
into
                        nearly independent pieces and cannot sustain 
integrated patterns of firing. This could explain why it feels as if 
consciousness
                        is vanishing in an almost all-or-none manner 
rather than diminishing progressively.<sup><a id="xref-ref-22-1" class="xref-bibr" href="#ref-22">20</a></sup></p>
                  </div>
                  <div id="sec-21" class="subsection">
                     <h3>The limited capacity of consciousness</h3>
                     <p id="p-98">It is often stated that the brain 
discards most of the incoming information, and that only a very small 
portion trickles into
                        consciousness. Thus, though the retina can 
transmit millions of bits per second, some estimates suggest that just a
 few bits
                        per second make it to consciousness (<a id="xref-ref-56-1" class="xref-bibr" href="#ref-56">Nørretranders, 1998</a>), which is abysmally little by engineering standards. Indeed, as shown by classic experiments, we cannot keep in mind more
                        than a few things at a time.
                     </p>
                     <p id="p-99">For the IIT, however, the 
informativeness of consciousness is not related to how many chunks of 
information a single experience
                        might contain. Instead, it relates to how many 
different states are ruled out. Since we can easily discriminate among 
trillions
                        of conscious states within a fraction of a 
second, the informativeness of conscious experience must be 
considerable. Presumably,
                        the so-called capacity limitation of 
consciousness reflects an upper bound on how many partially independent 
subprocesses
                        can be sustained within the main complex without
 compromising its integration.
                     </p>
                     <p id="p-100">Another consequence of the need for 
integration is the seemingly serial nature of consciousness. Since a 
complex constitutes
                        a single entity, it must move from one global 
state to another, and its temporal evolution must follow a single 
trajectory.
                        Indeed, dual-task paradigms and the 
psychological refractory period show that decisions or choices can only 
occur one at a
                        time (<a id="xref-ref-58-1" class="xref-bibr" href="#ref-58">Pashler, 1998</a>). Such choices take around 150 milliseconds, a figure remarkably close to the lower limit of the time typically needed for
                        conscious integration.
                     </p>
                     <p id="p-101">More generally, although transmitting
 and storing information is relatively cheap and easy, generating 
integrated information
                        would seem to be more expensive and difficult. 
Ensuring that a system forms a complex (integration) requires many 
connections
                        per element, and connections are usually 
expensive. At the same time, ensuring that the complex can discriminate 
among a large
                        number of states (information) requires that 
connections are patterned so that elements are both functionally 
specialized
                        and capable of acting as a single entity, which 
is usually difficult. Thus, it may be more fitting to say that the 
brain,
                        rather than discarding information, sifts 
through the chaff to extract precious kernels of integrated information.
 To use
                        another metaphor, if information were like 
carbon, mere information would be like a heap of coal, and integrated 
information
                        like a precious diamond.
                     </p>
                  </div>
                  <div id="sec-22" class="subsection">
                     <h3>Conscious artifacts?</h3>
                     <p id="p-102">Many scientists think that other species beyond humans are likely to be conscious (<a id="xref-ref-51-4" class="xref-bibr" href="#ref-51">Koch, 2004</a>)
 based on commonalities of behavior and on the overall similarity 
between their corticothalamic system and ours. But when
                        it comes to species that have radically 
different neural organization, such as fruit flies, or even more when 
one considers
                        man-made artifacts, arguments from analogy lose 
their strength, and it is hard to know what to think. The IIT has a 
straightforward
                        position on this issue: to the extent that a 
mechanism is capable of generating integrated information, no matter 
whether
                        it is organic or not, whether it is built of 
neurons or of silicon chips, and independent of its ability to report, 
it will
                        have consciousness. Thus, the theory implies 
that it should be possible to construct highly conscious artifacts by 
endowing
                        them with a complex of high Φ (<a id="xref-ref-52-1" class="xref-bibr" href="#ref-52">Koch and Tononi, 2008</a>). Moreover, it should be possible to design the quality of their conscious experience by appropriately structuring their
                        effective information matrix.
                     </p>
                     <p id="p-103">Such a position should not be read as
 implying that building conscious artifacts may be easy, or that many 
existing man-made
                        products, especially “complicated” ones, should 
be expected to have high values of Φ. The conditions needed to build 
complexes
                        of high Φ, such as a combination of functional 
specialization and integration, are apparently not easy to achieve. 
Moreover,
                        computer simulations suggest that seemingly 
“complicated” networks with many nodes and connections, whose connection
 diagram
                        superficially suggests a high level of 
“integration,” usually turn out to break down into small local complexes
 of low Φ,
                        or to form a single entity with a small 
repertoire of states and therefore also of low Φ: a paradigmatic example
 is a network
                        with full connectivity, which can be shown to 
generate at most 1 bit of integrated information (<a id="xref-ref-36-10" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>).
 Though we do not know how to calculate the amount of integrated 
information, not to mention the shape of the qualia, generated
                        by structures such as a computer chip, the World
 Wide Web, or the proverbial network of Chinese talking on the phone (<a id="xref-ref-38-1" class="xref-bibr" href="#ref-38">Block, 1978</a>),
 it is likely that the same principles apply: high Φ requires a very 
special kind of complexity, not just having many elements
                        intricately linked. Just think of something as 
complex as the cerebellum and its negligible contribution to 
consciousness.
                     </p>
                     <p id="p-104">Whether certain kinds of random networks (<a id="xref-ref-68-2" class="xref-bibr" href="#ref-68">Tononi and Sporns, 2003</a>), or even periodic network such as grids (<a id="xref-ref-36-11" class="xref-bibr" href="#ref-36">Balduzzi and Tononi, 2008</a>),
 could achieve high values of Φ (albeit inefficiently) by simply 
increasing the number of elements remains to be determined.
                        The brain certainly exploits grid-like 
arrangements (as in early sensory areas) and certain kinds of 
near-random connectivity
                        (as in prefrontal areas and perhaps, at a finer 
scale, everywhere else). Moreover, the small world architecture of the 
cerebral
                        cortex and its hub-like backbone may be 
especially well-suited to integrating information (<a id="xref-ref-61-1" class="xref-bibr" href="#ref-61">Sporns <em>et al</em>., 2000</a>; <a id="xref-ref-48-2" class="xref-bibr" href="#ref-48">Hagmann <em>et al</em>., 2008</a>). At present, even for very small networks of just a dozen elements, the only way to increase Φ is by brute-force optimization,
                        which is clearly unfeasible for more realistic networks, or through adaptation to a rich environment (<a id="xref-ref-69-1" class="xref-bibr" href="#ref-69">Tononi <em>et al</em>., 1996</a>).
                     </p>
                  </div>
                  <div id="sec-23" class="subsection">
                     <h3>Consciousness and meaning</h3>
                     <p id="p-105">The notion of integrated information 
and, more generally, the set of informational relationships that 
constitute a quale,
                        are closely related to the notion of meaning 
and, more generally, semantics. Here I briefly discuss how meaning 
requires a
                        system capable of integrating information and, 
more specifically, how meaning is captured by concepts.
                     </p>
                     <p id="p-106">For the IIT, mechanisms generate 
meanings. Moreover, only the mechanisms within a single complex do so. A
 mechanism modifies
                        a probability distribution (the context to which
 it is applied) into another distribution, thereby specifying an 
informational
                        relationship. In essence, then, a mechanism 
rules out certain states and rules in others. Note the parallel with 
semantics,
                        where a sentence's meaning is specified by the 
possible worlds in which it is true and false. Also, as in semantics, 
the meaning
                        changes depending on the context in which the 
mechanism acts. For the IIT, however, meaning is only meaningful within a
 complex—mechanisms
                        belonging to disjoint complexes do not generate 
meaning. In fact, what is meaningful is each individual experience, and 
its
                        meaning is completely and univocally specified 
by the shape of its quale. For example, a photodiode<sup><a id="xref-ref-24-1" class="xref-bibr" href="#ref-24">22</a></sup> generating a single q-arrow means (<em>i.e</em>., specifies) very little, whereas a large and complex quale means (<em>i.e</em>.,
 specifies) much more. The IIT is also precise about the possible worlds
 that need be considered: they are the states encompassed
                        by the maximum entropy distribution of a 
complex. How meanings “in the head” of different subjects refer to the 
external world
                        is a different matter, which requires 
considering the matching between internal and external relationships 
(see below).
                     </p>
                     <p id="p-107">Recall that <em>concepts</em> are entangled q-arrows that group together certain states of affairs in a way that cannot be decomposed into the mere sum
                        of simpler groupings (see also <a id="xref-ref-46-3" class="xref-bibr" href="#ref-46">Feldman, 2003</a>). <a id="xref-fig-10-1" class="xref-fig" href="#F10">Figure 10</a> shows two systems comprising four input elements (sensors) and four output elements (detectors). The “copy” system (<a id="xref-fig-10-2" class="xref-fig" href="#F10">Fig. 10A</a>, similar to the camera example in <a id="xref-fig-2-4" class="xref-fig" href="#F2">Fig. 2</a>,
 left side) is such that each output element is connected to a different
 input element, implementing for each sensor-detector
                        couple the function “D = S.” The copy system 
relays all 4 bits in the input but, since it decomposes into four 
separate complexes,
                        it generates no integrated information. Each 
sensor-detector couple generates 1 bit of integrated information and a 
single
                        informational relationship (q-arrow), 
corresponding to the simplest possible concept: that things are one way 
rather than
                        another way (just like the photodiode in <a id="xref-fig-1-2" class="xref-fig" href="#F1">Fig. 1</a>).
                     </p>
                     <div id="F10" class="fig pos-float odd">
                        <div class="fig-inline"><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F10.expansion.html"><img alt="Figure 10." src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/F10.gif"></a><div class="callout"><span>View larger version:</span><ul class="callout-links">
                                 <li><a class="fig-inline-link" href="http://www.biolbull.org/content/215/3/216/F10.expansion.html">In this page</a></li>
                                 <li><a target="_blank" class="in-nw-vis" href="http://www.biolbull.org/content/215/3/216/F10.expansion.html">In a new window</a></li>
                              </ul>
                              <ul class="fig-services"></ul>
                           </div>
                        </div>
                        <div class="fig-caption"><span class="fig-label">Figure 10.</span> 
                           <p id="p-130" class="first-child"><strong>Meaning</strong>.
 (A) The “copy system.” Each output element is connected to a different 
input element, implementing for each sensor-detector
                              couple the function “D = S.” The copy 
system relays all four bits in the input but, since it decomposes into 
four separate
                              complexes, it generates no integrated 
information. Each sensor-detector couple generates 1 bit of integrated 
information and
                              a single informational relationship 
(q-arrow), corresponding to the simplest possible concept: that things 
are one way rather
                              than another way (just like the photodiode
 in <a id="xref-fig-1-3" class="xref-fig" href="#F1">Fig. 1</a>). (B) The “conceptual” system. Each output element receives connections from all four input elements, and performs a more
                              complex Boolean function on the input. The q-arrow generated by each output element (<em>i.e</em>.,
 by its afferent connections) is entangled (the information generated 
jointly by its four afferent connections is higher
                              than the sum of the information generated 
by each connection independently). An entangled q-arrow constitutes a <em>concept</em>.
 In this case, the first element being off means “even” input, the 
second on means “symmetrical,” the third off “non-contiguous,”
                              the fourth on “balanced.” The q-arrow 
generated by all afferents to output elements considered together is 
also entangled,
                              and means something like this: things are 
this particular way—an even, symmetrical, non-contiguous, balanced 
input—rather
                              than many different ways. The conceptual 
system has literally added <em>meaning</em> to the input string. 
Moreover, the conceptual system realizes this concept as a single 
entity—a complex having high integrated
                              information—rather than as a collection of
 smaller entities, each of which realizes only a partial concept.
                           </p>
                           <div class="sb-div caption-clear"></div>
                        </div>
                     </div>
                     <p id="p-108">Consider now the “conceptual” system (<a id="xref-fig-10-3" class="xref-fig" href="#F10">Fig. 10B</a>). In this case, each output element receives connections from all four input elements, and performs a more complex Boolean
                        function on the input.<sup><a id="xref-ref-25-1" class="xref-bibr" href="#ref-25">23</a></sup>
 For example, output element 5 could be implementing a “parity” function
 on the four input elements (it is on if an odd number
                        of inputs are on, and off otherwise); element 6 a
 “symmetry” function (on if the arrangement of on-and-off inputs is 
symmetric);
                        element 7 a “contiguity” function (on if 
on-or-off input elements are not separated by an element of the other 
sign); and
                        element 8 a “balance” function (on if there are 
an equal number of on and off input elements).<sup><a id="xref-ref-26-1" class="xref-bibr" href="#ref-26">24</a></sup> In this case, the q-arrow generated by each output element (<em>i.e</em>.,
 by its afferent connections) is entangled: the information generated 
jointly by its four afferent connections is higher
                        than the sum of the information generated by 
each connection independently (for example, the parity function can only
 be computed
                        when all inputs are considered together). As I 
mentioned above, an entangled q-arrow constitutes a <em>concept</em> in 
Q, here embodied in single output elements integrating globally over all
 four input elements. Moreover, in this case the
                        four output elements specify different concepts,
 and thus generate information about different aspects of the input 
string.<sup><a id="xref-ref-27-1" class="xref-bibr" href="#ref-27">25</a></sup>
 Thus, the first element being off means “even” input, the second on 
means “symmetrical,” the third off “non-contiguous,”
                        the fourth on “balanced.” The q-arrow generated 
by all afferents to the output elements taken together is also 
entangled:
                        the information generated jointly by all 
afferent connections is higher than the sum of the information generated
 independently
                        by the afferents to each output element,<sup><a id="xref-ref-28-1" class="xref-bibr" href="#ref-28">26</a></sup> meaning something like this: things are this particular way—an even, symmetrical, non-contiguous, balanced input—rather than
                        many different ways. The conceptual system has literally added <em>meaning</em>
 to the input string. Moreover, the conceptual system realizes this 
concept as a single entity—a complex having high integrated
                        information—rather than as a collection of 
smaller entities, each of which realizes only a partial concept.
                     </p>
                     <p id="p-109">Indeed, meaning is truly in the eye 
of the beholder: an input string as such is meaningless, but becomes 
meaningful the moment
                        it is “read” by a complex with a rich conceptual
 structure (corresponding to high Φ). Moreover, a complex with many 
different
                        concepts will “read” meaning into anything, 
whether the meaning is there or not. It goes without saying that it is a
 good
                        idea to build such complexes in such a way that 
its concepts are meaningful for interpreting the environment (for 
example,
                        because they help predict future inputs). 
Finally, the more a system is able to conceptualize, the more it 
“understands”;
                        or, if it was built to predict an environment, 
the more it “knows.” Imagine that you do not know Chinese and are 
presented
                        with a large number of Chinese characters. By 
and large, you will group them into the category (concept) of “must be 
something
                        in Chinese,” since they are all equivalent to 
you. After you have learned Chinese, however, each of the characters 
acquires
                        a new, individual meaning (this one is a this, 
and that one is a that)—the input is the same, but the meaning has 
grown.<sup><a id="xref-ref-29-1" class="xref-bibr" href="#ref-29">27</a></sup></p>
                  </div>
                  <div id="sec-24" class="subsection">
                     <h3>The richness of qualia space</h3>
                     <p id="p-110">People often marvel at the immensity 
of the known universe, and wonder about other possible universes that we
 may never know.
                        But perhaps even more awe-inspiring is the 
variety and complexity of nature around us. Just think of the number of 
different
                        shapes that surround us, and their remarkable 
internal organization (see cover). This is certainly true of nonliving 
things,
                        at multiple scales: think of crystals or, at a 
much grander scale, of mountains. But it is spectacularly true of living
 organisms,
                        also at multiple scales: from the vast catalog 
of proteins and protein complexes—all of different shapes—to the 
inventory
                        of cells, to that of organs, to the ramified 
tree of species, and within each species, to the panoply of different 
individuals.
                        One could go on, and note how much of our own 
creations in engineering, science, and art also represent the generation
 of
                        novel shapes, never seen before, again in 
astonishing variety. Perhaps most relevant in this context is to 
consider how even
                        more extraordinary shapes would appear if we 
could look at them in more than just three dimensions and at the most 
appropriate
                        level of organization. Take the brain at the 
synaptic level, and disentangle its connectional organization in all its
 complexity:
                        if one could visualize the intricacy of the 
“connectome” (<a id="xref-ref-62-1" class="xref-bibr" href="#ref-62">Sporns <em>et al</em>., 2005</a>) in a space of appropriate dimensionality, it would make for a remarkable shape indeed.
                     </p>
                     <p id="p-111">I mention all of this to come to a key aspect of the IIT: that experiences (<em>i.e</em>.,
 qualia) are shapes too. As remarkable as the “enchanted loom” of 
anatomical connectivity and firing patterns is, it pales
                        compared to the shape of an experience in qualia
 space. For example, the complex generating the quale in <a id="xref-fig-5-6" class="xref-fig" href="#F5">Figure 5</a>
 has four elements (one of them firing) and nine connections among them.
 This simple system specifies a quale or shape that
                        is described by 399 points in a 16-dimensional 
qualia space. It is hard to imagine what may be the complexity of the 
quale
                        generated by a sizable portion of our brain. Add
 to this that the main complex within our brain, whatever its precise 
makeup
                        in terms of neurons and connections, is 
presumably generating a different shape, just as remarkable, every few 
hundred milliseconds,
                        often morphing smoothly into another shape as 
new informational relationships are specified through its mechanisms 
entering
                        new states. Of course, we cannot dream of 
visualizing such shapes as qualia diagrams (we have a hard time with 
shapes generated
                        by three elements). And yet, from a different 
perspective, we see and hear such shapes all the time, from the inside, 
as it
                        were, since such shapes are actually the stuff 
our dreams are made of—indeed the stuff all experience is made of.
                     </p>
                  </div>
                  <div id="sec-25" class="subsection">
                     <h3>Consciousness and the world: matching informational relationships</h3>
                     <p id="p-112">Consciousness <em>qua</em> integrated
 information is intrinsic and thus solipsistic. In principle, it could 
exist in and of itself, without requiring
                        anything extrinsic to it, not even a function or
 purpose. For the IIT, as long as a system has the right internal 
architecture
                        and forms a complex capable of discriminating a 
large number of internal states, it would be highly conscious. Such a 
system
                        would not even need any contact with the 
external world, and it could be completely passive, watching its own 
states change
                        without having to act.<sup><a id="xref-ref-30-1" class="xref-bibr" href="#ref-30">28</a></sup>
 Depending on the informational relationships generated by its 
architecture, its qualia could be just as interesting as ours,
                        whether or not they have anything to do with the
 causal architecture of the external world. Strange as this may sound, 
the
                        theory says that it may be possible one day to 
construct a highly conscious, solipsistic entity.
                     </p>
                     <p id="p-113">Nevertheless, it is unlikely that a 
system having high Φ and interesting qualia would come to be by chance, 
but only by design
                        or selection. Brain mechanisms, including those 
inside the main complex, are what they are by virtue of a long 
evolutionary
                        history, individual development, and learning. 
Evolutionary history leads to the establishment of certain 
species-specific
                        traits encoded in the genome, including brains 
and means to interact with the environment. Development and epigenetic 
processes
                        lead to an appropriate scaffold of anatomical 
connections. Experience then refines neural connectivity in an ongoing 
manner
                        though plastic processes, leading to the 
idiosyncrasies of the individual “connectome” and the memories it 
embeds.
                     </p>
                     <p id="p-114">Since for the IIT, experiences are 
informational relationships generated by mechanisms, what is the 
relationship between the
                        structure of experience and the structure of the
 world? Again, this issue requires a comprehensive theoretical approach (<a id="xref-ref-69-2" class="xref-bibr" href="#ref-69">Tononi <em>et al</em>., 1996</a>;
 Balduzzi and Tononi, unpubl.), but the main idea is simple enough. 
Through natural selection, epigenesis, and learning,
                        informational relationships in the world mold 
informational relationships within the main complex that “resonate” best
 on
                        a commensurate spatial and temporal scale. 
Moreover, over time these relationships will be shaped by an organism's 
values,
                        to reflect relevance for survival. This process 
can be envisioned as the experiential analog of natural selection. As is
 well
                        known, selective processes act on organisms 
through differential survival to modify gene frequencies (genotype), 
which in
                        turn leads to the evolution of certain body 
forms and behaviors (extrinsic phenotype). Similarly, selective 
processes (<a id="xref-ref-45-1" class="xref-bibr" href="#ref-45">Edelman, 1987</a>)
 acting on synaptic connections through plastic changes modify brain 
mechanisms (neurotype), which in turn modifies informational
                        relationships inside the main complex (intrinsic
 phenotype<sup><a id="xref-ref-31-1" class="xref-bibr" href="#ref-31">29</a></sup>) and thereby consciousness itself. In this way, qualia—the shapes of experience—come to be molded, sculpted, and refined
                        by the informational structure of events in the world.
                     </p>
                     <p id="p-115">A working hypothesis is that the 
quantity of “matching” between the informational relationships inside a 
complex and the informational
                        structure of the world can be evaluated, at 
least in principle, by comparing the value of Φ when a complex is 
exposed to the
                        environment, to the value of Φ when the complex 
is isolated or “dreaming” (<a id="xref-ref-69-3" class="xref-bibr" href="#ref-69">Tononi <em>et al</em>., 1996</a>).
 Similarly, the quality of matching can be evaluated by how the shapes 
of qualia “resonate” with the environment: for example,
                        certain sub-shapes within a quale should 
“inflate” along certain dimensions when the complex is presented with 
appropriate
                        stimuli.
                     </p>
                     <p id="p-116">This working hypothesis also suggests
 that morphogenesis and natural selection may be responsible for a 
progressive increase
                        in the amount of integrated information 
generated by biological brains, and thus for the evolution of 
consciousness. This
                        is because, in organisms exposed to a rich 
environment, plastic processes tend to increase functional 
specialization, while
                        the brain's massive interconnectivity ensures 
neural and behavioral integration. In fact, it appears that as a system 
incorporates
                        statistical regularities from its environment 
and learns to predict it, its capacity for integrated information may 
grow (<a id="xref-ref-69-4" class="xref-bibr" href="#ref-69">Tononi <em>et al</em>., 1996</a>). It remains to be seen whether, based on the same principles, the construction of shapes even more extensive and complex
                        may be achieved through nonbiological means.
                     </p>
                     <p id="p-117">Finally, the integrated information approach offers a straightforward perspective on why consciousness would be useful (<a id="xref-ref-44-1" class="xref-bibr" href="#ref-44">Dennett, 1991</a>).
 By definition, a highly conscious experience is a discrimination among 
trillions of alternatives—it specifies that what
                        is the case is this particular state of affairs,
 which differs from a trillion other states of affairs in its own 
peculiar
                        way, and in a way that is imbued with 
evolutionary value. Equivalently, one can say that a quale of high Φ 
represents a discrimination
                        that is extremely context-sensitive, and thus 
likely to be useful. Experience is choice, and a highly conscious choice
 is
                        a choice that is both highly informed and highly
 integrated.
                     </p>
                     <p id="p-118">Recall the photodiode. For it, turning on specifies that things are one way rather than another. What things might be like,
                        it has 1 bit of a notion. For each of us, when the screen light turns on, the movie is about to begin.
                     </p>
                  </div>
               </div>
               <div class="section ack" id="ack-1">
                  <div class="section-nav"><a href="#sec-14" title="A Provisional Manifesto" class="prev-section-link"><span>Previous Section</span></a><a href="#fn-group-1" title="Footnotes" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>Acknowledgments</h2>
                  <p id="p-120">I thank David Balduzzi, Chiara Cirelli, and Lice Ghilardi for their help, and the McDonnell Foundation for support.</p>
               </div>
               <div class="section fn-group" id="fn-group-1">
                  <div class="section-nav"><a href="#ack-1" title="Acknowledgments" class="prev-section-link"><span>Previous Section</span></a><a href="#ref-list-1" title="Notes" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>Footnotes</h2>
                  <ul>
                     <li class="fn fn-group-article-title" id="fn-1">
                        <p id="p-119">Received 20 August 2008; accepted 10 October 2008.</p>
                     </li>
                  </ul>
               </div>
               <div class="section ref-list" id="ref-list-1">
                  <div class="section-nav"><a href="#fn-group-1" title="Footnotes" class="prev-section-link"><span>Previous Section</span></a><a href="#ref-list-2" title="Literature Cited" class="next-section-link"><span>Next Section</span></a></div>
                  <h2>Notes</h2>
                  <ol class="cit-list ref-use-labels">
                     <li><span class="ref-label">1.</span><a class="rev-xref-ref" href="#xref-ref-1-1" title="View reference 1 in text" id="ref-1">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.1">
                           <div class="cit-metadata unstructured">One 
could say that the theory starts from two basic phenomenological 
postulates—(i) experience is informative; (ii) experience
                              is integrated—which are assumed to be 
immediately evident (or at least should be after going through the two 
thought experiments).
                              In principle, the theory, including the 
mathematical formulation and its corollaries, should be derivable from 
these postulates.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">2.</span><a class="rev-xref-ref" href="#xref-ref-2-1" title="View reference 2 in text" id="ref-2">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.2">
                           <div class="cit-metadata unstructured">Note that two different distributions over the same states have relative entropy &gt;0 even if they have the same entropy.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">3.</span><a class="rev-xref-ref" href="#xref-ref-3-1" title="View reference 3 in text" id="ref-3">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.3">
                           <div class="cit-metadata"><cite>One could paraphrase a classic definition of information (Bateson, 1972) and say that <span class="cit-source">information is a difference that made a difference</span> (the actual repertoire that can be discriminated by a given mechanism in a given state).</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">4.</span><a class="rev-xref-ref" href="#xref-ref-4-1" title="View reference 4 in text" id="ref-4">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.4">
                           <div class="cit-metadata"><cite>In other words, <span class="cit-source">integrated information is a difference that made a difference to a system, to the extent that the system constitutes a single
                                    entity.</span></cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">5.</span><a class="rev-xref-ref" href="#xref-ref-5-1" title="View reference 5 in text" id="ref-5">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.5">
                           <div class="cit-metadata unstructured">A phenomenon in which an observer may fail to perceive an image that is presented after a rapid succession of other images.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">6.</span><a class="rev-xref-ref" href="#xref-ref-6-1" title="View reference 6 in text" id="ref-6">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.6">
                           <div class="cit-metadata unstructured">A condition in which, when different images are presented to each eye, instead of seeing them superimposed, one perceives
                              one image at a time, and which image one perceives switches every 2 seconds.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">7.</span><a class="rev-xref-ref" href="#xref-ref-7-1" title="View reference 7 in text" id="ref-7">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.7">
                           <div class="cit-metadata unstructured">The set of all subsets of connections forms a lattice (or more precisely a <em>logic</em>, characterized by an ordering relationship, join and meet operators, and a complement operator).
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">8.</span><a class="rev-xref-ref" href="#xref-ref-8-1" title="View reference 8 in text" id="ref-8">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.8">
                           <div class="cit-metadata unstructured">Univocally
 implies, for example, that the “inverted spectrum” is impossible: a 
given shape (quale) specifies red and only
                              red, another one green and only green. In 
turn, this implies that the neural mechanisms underlying the perception 
of red and
                              green cannot be completely symmetric 
(Palmer, 1999).
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">9.</span><a class="rev-xref-ref" href="#xref-ref-9-1" title="View reference 9 in text" id="ref-9">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.9">
                           <div class="cit-metadata unstructured">The set of all possible shapes generated by all possible systems corresponds to the set of all possible experiences.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">10.</span><a class="rev-xref-ref" href="#xref-ref-10-1" title="View reference 10 in text" id="ref-10">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.10">
                           <div class="cit-metadata unstructured">More precisely, the lesion collapses all q-arrows generated by r starting from any <em>context;</em> that is, it folds the quale along the <em>q-fold</em> specified by r.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">11.</span><a class="rev-xref-ref" href="#xref-ref-11-1" title="View reference 11 in text" id="ref-11">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.11">
                           <div class="cit-metadata unstructured">In 
lattices there is often a duality between elements (extensions) and 
attributes (intensions). Going up the lattice we move
                              from elementary connections taken in 
isolation to all connections taken together. Going down the lattice, or 
up its dual,
                              we move from the elementary attributes of a
 fully specified experience (the redness of red) to an undifferentiated 
experience,
                              all of whose attributes are unspecified.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">12.</span><a class="rev-xref-ref" href="#xref-ref-12-1" title="View reference 12 in text" id="ref-12">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.12">
                           <div class="cit-metadata unstructured">In 
essence, the very existence of a functional mechanism in a given state 
is saying something like this: Given that I am a
                              certain mechanism in good order, and that I
 am a certain state, things must have been this way, rather than other 
ways. In
                              this sense, the information the mechanism 
generates is a statement about the universe made from its own intrinsic 
perspective—indeed,
                              the only statement it can possibly make. 
Another way of saying this is that the mechanism is generating 
information by making
                              an observation or <em>measurement</em>—where the mechanism is both the observer and the observed. In short, every (integrated) mechanism is an observer (of itself),
                              and the state it is in is the result of that observation.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">13.</span><a class="rev-xref-ref" href="#xref-ref-13-1" title="View reference 13 in text" id="ref-13">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.13">
                           <div class="cit-metadata unstructured">There may be concentrations of such bright objects elsewhere in the universe, but at present we have no positive evidence.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">14.</span><a class="rev-xref-ref" href="#xref-ref-14-1" title="View reference 14 in text" id="ref-14">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.14">
                           <div class="cit-metadata unstructured">The 
notion of integrated information can in principle be extended to 
encompass quantum information. There are intriguing parallels
                              between integrated information and quantum
 notions. Consider for example: (i) quantum superposition and the 
potential repertoire
                              of a mechanism (in a sense, before it is 
engaged, a mechanisms exists in a superposition of all its possible 
output states);
                              (ii) decoherence and the actual repertoire
 of a mechanism (when the mechanism is engaged and enters a certain 
state, it collapses
                              the potential repertoire into the actual 
repertoire); (iii) quantum entanglement and integrated information (to 
the extent
                              that one cannot perturb two elements 
independently, they are informationally one).
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.15">
                           <div class="cit-metadata unstructured">There 
are also some points of contact between the notion of integrated 
information and the approach advocated by relational
                              quantum mechanics (Rovelli, 1996). The 
relational approach claims that system states exist only in relation to 
an observer,
                              where an observer is another system (or a 
part of the same system). By contrast, the IIT says that a system can 
observe itself,
                              though it can only do so by “measuring” 
its previous state. More generally, for the IIT, only complexes, and not
 arbitrary
                              collections of elements, are real 
observers, whereas physics is usually indifferent to whether information
 is integrated or
                              not.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.16">
                           <div class="cit-metadata unstructured">Other 
interesting issues concern the relation between the conservation of 
information and the apparent increase in integrated
                              information, and the finiteness of 
information (even in terms of qubits, the amount of information 
available to a physical
                              system is finite). More generally, it 
seems useful to consider some of the paradoxes of information in physics
 from the intrinsic
                              perspective, that is, as integrated 
information, where the observer is one and the same as the observed.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">15.</span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.17">
                           <div class="cit-metadata unstructured">Φ would be high for one specific firing pattern; for all other ones it would be very low.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">16.</span><a class="rev-xref-ref" href="#xref-ref-18-1" title="View reference 16 in text" id="ref-18">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.18">
                           <div class="cit-metadata unstructured">Here I
 ignore the issue of whether serial and parallel mechanisms are 
equivalent from the perspective of integrated information,
                              as well as the issue of analog and digital
 computation (or quantum computation). In general, it must be asked to 
what extent
                              two systems that are implemented 
differently actually specify the same complex and qualia when analyzed 
at the proper spatio-temporal
                              grain.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">17.</span><a class="rev-xref-ref" href="#xref-ref-19-1" title="View reference 17 in text" id="ref-19">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.19">
                           <div class="cit-metadata unstructured">It is worth reiterating that a full description is practically out of the question for any realistic system.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">18.</span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.20">
                           <div class="cit-metadata unstructured">More appropriately, Mary should be like the achromatopsic patient mentioned above, since otherwise she might be able to dream
                              in color.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">19.</span><a class="rev-xref-ref" href="#xref-ref-21-1" title="View reference 19 in text" id="ref-21">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.21">
                           <div class="cit-metadata unstructured">Although the quality of the photodiode's consciousness is the same quality generated by a binary thermistor, and many other
                              simple mechanisms.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">20.</span><a class="rev-xref-ref" href="#xref-ref-22-1" title="View reference 20 in text" id="ref-22">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.22">
                           <div class="cit-metadata unstructured">Our 
ability to judge gradations in the level of consciousness when absolute 
levels are low may also be poor. As a loose metaphor,
                              consider temperature. We are good at 
judging temperature as long as it fluctuates around the usual range, say
 between −50
                              and +100 °C. However, when temperature 
falls below that range, we become much less precise: both −200 and 
−273°C are inconceivably
                              cold to us, and we certainly would not 
judge −200 to be much warmer than absolute zero. Similarly, a complex 
generating 1
                              or 10 bits of integrated information may 
feel a bit different (or rather 9 bits different), but it may feel like 
so little
                              that, compared to our usual levels of 
consciousness, it essentially feels like nothing. Which is why, of 
course, it is good
                              to have a thermometer or a Φ-meter.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">21.</span><a class="rev-xref-ref" href="#xref-ref-23-1" title="View reference 21 in text" id="ref-23">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.23">
                           <div class="cit-metadata unstructured">An 
optical metaphor can again be useful: things come crisply into existence
 at a certain focal distance, and with a certain
                              exposure time. At shorter or longer focal 
distances things vanish out of focus: if exposure time is too short, 
they do not
                              register; if it is too long, they blur.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">22.</span><a class="rev-xref-ref" href="#xref-ref-24-1" title="View reference 22 in text" id="ref-24">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.24">
                           <div class="cit-metadata unstructured">A photodiode or any other complex generating a quale consisting of just a single q-arrow.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">23.</span><a class="rev-xref-ref" href="#xref-ref-25-1" title="View reference 23 in text" id="ref-25">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.25">
                           <div class="cit-metadata unstructured">Here I ignore the issue of decomposing complex Boolean functions into elementary mechanisms.</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">24.</span><a class="rev-xref-ref" href="#xref-ref-26-1" title="View reference 24 in text" id="ref-26">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.26">
                           <div class="cit-metadata unstructured">Note that each of these functions should be thought of as implemented according to its minimal formula (of shortest description
                              length, <em>i.e</em>., of minimal complexity). Clearly, minimal formulas that involve four inputs are more complex than formulas involving just
                              one input (the parity function, for instance, is notoriously incompressible).
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">25.</span><a class="rev-xref-ref" href="#xref-ref-27-1" title="View reference 25 in text" id="ref-27">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.27">
                           <div class="cit-metadata unstructured">While 
the particular combination of concepts described here was chosen for its
 familiarity (parity, symmetry, contiguousness,
                              balance) rather than for informational 
efficiency, one can envision Boolean functions that realize “optimal” 
sets of concepts
                              from the point of view of integrated 
information. For example, the four functions may be chosen so that, on 
average, the set
                              of four output units jointly generate as 
much integrated information as possible, up to the theoretical maximum 
of 4 bits
                              of Φ for every input string (by contrast, 
the “copy system,” while transmitting all 4 bits in the input, would 
generate 4
                              times 1 bit of integrated information). 
Obviously, building a system that could respond optimally to a large set
 of input
                              strings is exceedingly difficult (if at 
all possible), especially considering the need to build such a system 
using simple
                              Boolean functions as building blocks.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">26.</span><a class="rev-xref-ref" href="#xref-ref-28-1" title="View reference 26 in text" id="ref-28">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.28">
                           <div class="cit-metadata unstructured">Again, it is difficult to build an optimal conceptual system that can preserve all the information in the input, corresponding
                              in this case to 4 bits of integrated information for every input string.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">27.</span><a class="rev-xref-ref" href="#xref-ref-29-1" title="View reference 27 in text" id="ref-29">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.29">
                           <div class="cit-metadata unstructured">The 
extreme case is watching noisy “snow” patterns flickering on a TV 
screen. We treat the overwhelming majority of TV frames
                              as equivalent, under the concept of “TV 
snow.” If one were an optimal conceptual system, however, each frame 
would be conceptualized
                              as its own very particular kind of pattern
 (say exhibiting a certain amount of 17th order symmetries, another 
amount of 11th
                              order symmetries, belonging to the 6th 
class of contiguousness, <em>etc</em>.). In a sense, every noisy frame would be read as an astonishingly deep, rich, meaningful and unique pattern, perhaps as
                              a work of art.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">28.</span><a class="rev-xref-ref" href="#xref-ref-30-1" title="View reference 28 in text" id="ref-30">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.30">
                           <div class="cit-metadata unstructured">Dreams
 prove that an adult brain does not need the outside world to generate 
experience “here and now”: the mechanisms of
                              the main complex within the brain are 
sufficient, all by themselves, to generate the informational 
relationships that constitute
                              experience. Not to mention that in dreams 
we tend to be remarkably passive.
                           </div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label">29.</span><a class="rev-xref-ref" href="#xref-ref-31-1" title="View reference 29 in text" id="ref-31">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.31">
                           <div class="cit-metadata unstructured">Indeed, the shape of experience can be said to be the quintessential “phenotype.”</div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                  </ol>
               </div>
               <div class="section ref-list" id="ref-list-2">
                  <div class="section-nav"><a href="#ref-list-1" title="Notes" class="prev-section-link"><span>Previous Section</span></a><div class="nav-placeholder">&nbsp;</div>
                  </div>
                  <h2>Literature Cited</h2>
                  <ol class="cit-list ref-use-labels">
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-32-1" title="View reference in text" id="ref-32">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.32">
                           <div class="cit-metadata"><cite><strong>Albus, J. S., G. A. Bekey, J. H. Holland, N. G. Kanwisher, J. L. Krichmar, M. Mishkin, </strong><strong><em>et al</em></strong><strong>. </strong><span class="cit-pub-date">2007</span>. A proposal for a Decade of the Mind initiative. <span class="cit-source">Science</span> <span class="cit-vol">317</span>: <span class="cit-fpage">1321</span>.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-33-1" title="View reference in text" id="ref-33">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.33">
                           <div class="cit-metadata"><cite><strong>Alkire, M. T., A. G. Hudetz, and G. Tononi. </strong><span class="cit-pub-date">2008</span>. Consciousness and anesthesia. <span class="cit-source">Science</span> <span class="cit-vol">322</span>: <span class="cit-fpage">876</span>–880.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=sci&amp;resid=322/5903/876" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-34-1" title="View reference in text" id="ref-34">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.34">
                           <div class="cit-metadata"><cite><strong>Baars, B. J. </strong><span class="cit-pub-date">1988</span>. <span class="cit-source">A Cognitive Theory of Consciousness.</span> Cambridge University Press, New York.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-35-1" title="View reference in text" id="ref-35">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.35">
                           <div class="cit-metadata"><cite><strong>Bachmann, T. </strong><span class="cit-pub-date">2000</span>. <span class="cit-source">Microgenetic Approach to the Conscious Mind.</span> John Benjamins, Philadelphia.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-36-1" title="View reference in text" id="ref-36">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.36">
                           <div class="cit-metadata"><cite><strong>Balduzzi, D., and G. Tononi. </strong><span class="cit-pub-date">2008</span>. Integrated information in discrete dynamical systems: motivation and theoretical framework. <span class="cit-source">PLoS Comput. Biol.</span> <span class="cit-vol">4</span>: <span class="cit-fpage">e1000091</span>.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1371/journal.pcbi.1000091&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=18551165&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.37">
                           <div class="cit-metadata"><cite><strong>Bateson, G. </strong><span class="cit-pub-date">1972</span>. <span class="cit-source">Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution, and Epistemology.</span> Chandler, San Francisco.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-38-1" title="View reference in text" id="ref-38">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.38">
                           <div class="cit-metadata"><cite><strong>Block, N., ed. </strong><span class="cit-pub-date">1978</span>. <span class="cit-source">Trouble with Functionalism</span>, Vol. <span class="cit-vol">9</span>. Minnesota University Press, Minneapolis.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-39-1" title="View reference in text" id="ref-39">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.39">
                           <div class="cit-metadata"><cite><strong>Blumenfeld, H., and J. Taylor. </strong><span class="cit-pub-date">2003</span>. Why do seizures cause loss of consciousness? <span class="cit-source">Neuroscientist</span> <span class="cit-vol">9</span>: <span class="cit-fpage">301</span>–310.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=spnro&amp;resid=9/5/301" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-40-1" title="View reference in text" id="ref-40">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.40">
                           <div class="cit-metadata"><cite><strong>Bower, J. M. </strong><span class="cit-pub-date">2002</span>. The organization of cerebellar cortical circuitry revisited: implications for function. <span class="cit-source">Ann. N.Y. Acad. Sci.</span> <span class="cit-vol">978</span>: <span class="cit-fpage">135</span>–155.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1111/j.1749-6632.2002.tb07562.x&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=12582048&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a><a href="http://www.biolbull.org/external-ref?access_num=000180980000012&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-41-1" title="View reference in text" id="ref-41">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.41">
                           <div class="cit-metadata"><cite><strong>Cover, T. M., and J. A. Thomas. </strong><span class="cit-pub-date">2006</span>. <span class="cit-source">Elements of Information Theory</span>, 2nd ed. Wiley-Interscience, Hoboken, NJ.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-42-1" title="View reference in text" id="ref-42">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.42">
                           <div class="cit-metadata"><cite><strong>Crick, F., and C. Koch. </strong><span class="cit-pub-date">2003</span>. A framework for consciousness. <span class="cit-source">Nat. Neurosci.</span> <span class="cit-vol">6</span>: <span class="cit-fpage">119</span>–126.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1038/nn0203-119&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=12555104&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a><a href="http://www.biolbull.org/external-ref?access_num=000180669100011&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-43-1" title="View reference in text" id="ref-43">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.43">
                           <div class="cit-metadata"><cite><strong>Dehaene, S., C. Sergent, and J. P. Changeux. </strong><span class="cit-pub-date">2003</span>. A neuronal network model linking subjective reports and objective physiological data during conscious perception. <span class="cit-source">Proc. Natl. Acad. Sci. USA</span> <span class="cit-vol">100</span>: <span class="cit-fpage">8520</span>–8525.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=pnas&amp;resid=100/14/8520" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-44-1" title="View reference in text" id="ref-44">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.44">
                           <div class="cit-metadata"><cite><strong>Dennett, D. C. </strong><span class="cit-pub-date">1991</span>. <span class="cit-source">Consciousness Explained.</span> Little, Brown, Boston, MA.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-45-1" title="View reference in text" id="ref-45">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.45">
                           <div class="cit-metadata"><cite><strong>Edelman, G. M. </strong><span class="cit-pub-date">1987</span>. <span class="cit-source">Neural Darwinism: The Theory of Neuronal Group Selection.</span> BasicBooks, New York.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-46-1" title="View reference in text" id="ref-46">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.46">
                           <div class="cit-metadata"><cite><strong>Feldman, J. </strong><span class="cit-pub-date">2003</span>. A catalog of Boolean concepts. <span class="cit-source">J. Math. Psychol.</span> <span class="cit-vol">47</span>: <span class="cit-fpage">75</span>–89.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=000183069500005&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-47-1" title="View reference in text" id="ref-47">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.47">
                           <div class="cit-metadata"><cite><strong>Gazzaniga, M. S. </strong><span class="cit-pub-date">2005</span>. Forty-five years of split-brain research and still going strong. <span class="cit-source">Nat. Rev. Neurosci.</span> <span class="cit-vol">6</span>: <span class="cit-fpage">653</span>–659.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1038/nrn1723&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=16062172&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a><a href="http://www.biolbull.org/external-ref?access_num=000230879500017&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-48-1" title="View reference in text" id="ref-48">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.48">
                           <div class="cit-metadata"><cite><strong>Hagmann, P., L. Cammoun, X. Gigandet, R. Meuli, C. J. Honey, V. J. Wedeen, </strong><strong><em>et al</em></strong><strong>. </strong><span class="cit-pub-date">2008</span>. Mapping the structural core of human cerebral cortex. <span class="cit-source">PLoS Biol.</span> <span class="cit-vol">6</span>: <span class="cit-fpage">e159</span>.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1371/journal.pbio.0060159&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=18597554&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-49-1" title="View reference in text" id="ref-49">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.49">
                           <div class="cit-metadata"><cite><strong>Hobson, J. A., E. F. Pace-Schott, and R. Stickgold. </strong><span class="cit-pub-date">2000</span>. Dreaming and the brain: toward a cognitive neuroscience of conscious states. <span class="cit-source">Behav. Brain Sci.</span> <span class="cit-vol">23</span>: <span class="cit-fpage">793</span>–842.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1017/S0140525X00003976&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=11515143&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a><a href="http://www.biolbull.org/external-ref?access_num=000170102400001&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-50-1" title="View reference in text" id="ref-50">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.50">
                           <div class="cit-metadata"><cite><strong>Jackson, F. </strong><span class="cit-pub-date">1986</span>. What Mary didn't know. <span class="cit-source">J. Philos.</span> <span class="cit-vol">83</span>: <span class="cit-fpage">291</span>–295.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.2307/2026143&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=A1986C413200004&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-51-1" title="View reference in text" id="ref-51">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.51">
                           <div class="cit-metadata"><cite><strong>Koch, C. </strong><span class="cit-pub-date">2004</span>. <span class="cit-source">The Quest for Consciousness: A Neurobiological Approach.</span> Roberts, Denver, CO.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-52-1" title="View reference in text" id="ref-52">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.52">
                           <div class="cit-metadata"><cite><strong>Koch, C., and G. Tononi. </strong><span class="cit-pub-date">2008</span>. Can machines be conscious? <span class="cit-source">Spectrum IEEE</span> <span class="cit-vol">45</span>: <span class="cit-fpage">55</span>–59.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-53-1" title="View reference in text" id="ref-53">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.53">
                           <div class="cit-metadata"><cite><strong>Koch, C., and N. Tsuchiya. </strong><span class="cit-pub-date">2007</span>. Attention and consciousness: two distinct brain processes. <span class="cit-source">Trends Cogn. Sci.</span> <span class="cit-vol">11</span>: <span class="cit-fpage">16</span>–22.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1016/j.tics.2006.10.012&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=17129748&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a><a href="http://www.biolbull.org/external-ref?access_num=000243742400006&amp;link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">Web of Science</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-54-1" title="View reference in text" id="ref-54">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.54">
                           <div class="cit-metadata"><cite><strong>Massimini, M., F. Ferrarelli, R. Huber, S. K. Esser, H. Singh, and G. Tononi. </strong><span class="cit-pub-date">2005</span>. Breakdown of cortical effective connectivity during sleep. <span class="cit-source">Science</span> <span class="cit-vol">309</span>: <span class="cit-fpage">2228</span>–2232.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=sci&amp;resid=309/5744/2228" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-55-1" title="View reference in text" id="ref-55">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.55">
                           <div class="cit-metadata"><cite><strong>Massimini, M., F. Ferrarelli, S. K. Esser, B. A. Riedner, R. Huber, M. Murphy, </strong><strong><em>et al</em></strong><strong>. </strong><span class="cit-pub-date">2007</span>. Triggering sleep slow waves by transcranial magnetic stimulation. <span class="cit-source">Proc. Natl. Acad. Sci. USA</span> <span class="cit-vol">104</span>: <span class="cit-fpage">8496</span>–8501.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=pnas&amp;resid=104/20/8496" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-56-1" title="View reference in text" id="ref-56">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.56">
                           <div class="cit-metadata"><cite><strong>Nørretranders, T. </strong><span class="cit-pub-date">1998</span>. <span class="cit-source">The User Illusion: Cutting Consciousness Down to Size.</span> Viking, New York.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.57">
                           <div class="cit-metadata"><cite><strong>Palmer, S. E. </strong><span class="cit-pub-date">1999</span>. Color, consciousness, and the isomorphism constraint. <span class="cit-source">Behav. Brain Sci.</span> <span class="cit-vol">22</span>: <span class="cit-fpage">923</span>–943; discussion 944–989.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=11301573&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-58-1" title="View reference in text" id="ref-58">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.58">
                           <div class="cit-metadata"><cite><strong>Pashler, H. E. </strong><span class="cit-pub-date">1998</span>. <span class="cit-source">The Psychology of Attention.</span> MIT Press, Cambridge, MA.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-59-1" title="View reference in text" id="ref-59">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.59">
                           <div class="cit-metadata"><cite><strong>Posner, J. B., and F. Plum. </strong><span class="cit-pub-date">2007</span>. <span class="cit-source">Plum and Posner's Diagnosis of Stupor and Coma</span>, 4th ed. Oxford University Press, New York.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><div class="cit ref-cit ref-other no-rev-xref" id="cit-215.3.216.60">
                           <div class="cit-metadata"><cite><strong>Rovelli, C. </strong><span class="cit-pub-date">1996</span>. Relational quantum mechanics. <span class="cit-source">Int. J. Theor. Phys.</span> <span class="cit-vol">35</span>: <span class="cit-fpage">1637</span>–1678.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-61-1" title="View reference in text" id="ref-61">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.61">
                           <div class="cit-metadata"><cite><strong>Sporns, O., G. Tononi, and G. M. Edelman. </strong><span class="cit-pub-date">2000</span>. Theoretical neuroanatomy: relating anatomical and functional connectivity in graphs and cortical connection matrices. <span class="cit-source">Cereb. Cortex</span> <span class="cit-vol">10</span>: <span class="cit-fpage">127</span>–141.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=cercor&amp;resid=10/2/127" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-62-1" title="View reference in text" id="ref-62">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.62">
                           <div class="cit-metadata"><cite><strong>Sporns, O., G. Tononi, and R. Kotter. </strong><span class="cit-pub-date">2005</span>. The human connectome: a structural description of the human brain. <span class="cit-source">PLoS Comput. Biol.</span> <span class="cit-vol">1</span>: <span class="cit-fpage">e42</span>.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1371/journal.pcbi.0010042&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=16201007&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-63-1" title="View reference in text" id="ref-63">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.63">
                           <div class="cit-metadata"><cite><strong>Steriade, M., I. Timofeev, and F. Grenier. </strong><span class="cit-pub-date">2001</span>. Natural waking and sleep states: a view from inside neocortical neurons. <span class="cit-source">J. Neurophysiol.</span> <span class="cit-vol">85</span>: <span class="cit-fpage">1969</span>–1985.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=jn&amp;resid=85/5/1969" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-64-1" title="View reference in text" id="ref-64">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.64">
                           <div class="cit-metadata"><cite><strong>Tononi, G. </strong><span class="cit-pub-date">2001</span>. Information measures for conscious experience. <span class="cit-source">Arch. Ital. Biol.</span> <span class="cit-vol">139</span>: <span class="cit-fpage">367</span>–371.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=11603079&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-65-1" title="View reference in text" id="ref-65">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.65">
                           <div class="cit-metadata"><cite><strong>Tononi, G. </strong><span class="cit-pub-date">2004</span>. An information integration theory of consciousness. <span class="cit-source">BMC Neurosci.</span> <span class="cit-vol">5</span>: <span class="cit-fpage">42</span>.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1186/1471-2202-5-42&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=15522121&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-66-1" title="View reference in text" id="ref-66">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.66">
                           <div class="cit-metadata"><cite><strong>Tononi, G., and G. M. Edelman. </strong><span class="cit-pub-date">1998</span>. Consciousness and complexity. <span class="cit-source">Science</span> <span class="cit-vol">282</span>: <span class="cit-fpage">1846</span>–1851.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=sci&amp;resid=282/5395/1846" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-67-1" title="View reference in text" id="ref-67">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.67">
                           <div class="cit-metadata"><cite><strong>Tononi, G., and S. Laureys. </strong><span class="cit-pub-date">2008</span>. The neurology of consciousness: an overview. Pp. <span class="cit-fpage">375</span>–412 in <span class="cit-source">The Neurology of Consciousness</span>, S. Laureys and G. Tononi, eds. Elsevier, Oxford.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-68-1" title="View reference in text" id="ref-68">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.68">
                           <div class="cit-metadata"><cite><strong>Tononi, G., and O. Sporns. </strong><span class="cit-pub-date">2003</span>. Measuring information integration. <span class="cit-source">BMC Neurosci.</span> <span class="cit-vol">4</span>: <span class="cit-fpage">31</span>.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1186/1471-2202-4-31&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=14641936&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-69-1" title="View reference in text" id="ref-69">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.69">
                           <div class="cit-metadata"><cite><strong>Tononi, G., O. Sporns, and G. M. Edelman. </strong><span class="cit-pub-date">1996</span>. A complexity measure for selective matching of signals by the brain. <span class="cit-source">Proc. Natl. Acad Sci. USA</span> <span class="cit-vol">93</span>: <span class="cit-fpage">3422</span>–3427.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/cgi/ijlink?linkType=ABST&amp;journalCode=pnas&amp;resid=93/8/3422" class="cit-ref-sprinkles cit-ref-sprinkles-ijlinks"><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-70-1" title="View reference in text" id="ref-70">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.70">
                           <div class="cit-metadata"><cite><strong>van Zandvoort, M. J., T. C. Nijboer, and E. de Haan. </strong><span class="cit-pub-date">2007</span>. Developmental colour agnosia. <span class="cit-source">Cortex</span> <span class="cit-vol">43</span>: <span class="cit-fpage">750</span>–757.</cite></div>
                           <div class="cit-extra"><a href="http://www.biolbull.org/external-ref?access_num=10.1016/S0010-9452%2808%2970503-3&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-webofscience">CrossRef</a><a href="http://www.biolbull.org/external-ref?access_num=17710826&amp;link_type=MED" class="cit-ref-sprinkles cit-ref-sprinkles-medline">Medline</a></div>
                        </div>
                     </li>
                     <li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-71-1" title="View reference in text" id="ref-71">↵</a><div class="cit ref-cit ref-other" id="cit-215.3.216.71">
                           <div class="cit-metadata"><cite><strong>Wheeler, J. A., and K. W. Ford. </strong><span class="cit-pub-date">1998</span>. <span class="cit-source">Geons, Black Holes, and Quantum Foam: A Life in Physics</span>, 1st ed. Norton, New York.</cite></div>
                           <div class="cit-extra"></div>
                        </div>
                     </li>
                  </ol>
               </div><span class="highwire-journal-article-marker-end"></span></div><span id="related-urls"></span><div xmlns="http://www.w3.org/1999/xhtml" id="cited-by"><h2>Articles citing this article</h2><ul class="cited-by-list"><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Network structure and dynamics of the mental workspace </span> <cite><abbr title="PNAS" class="site-title">Proc. Natl. Acad. Sci. USA</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">110<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">16277</span><span class="cit-sep">-</span><span class="cit-last-page">16282</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck pnas;110/40/16277 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.pnas.org/cgi/content/abstract/110/40/16277" rel="abstract">Abstract</a></li><li><a href="http://www.pnas.org/cgi/content/full/110/40/16277" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.pnas.org/cgi/reprint/110/40/16277" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Breakdown of long-range temporal dependence in default mode and attention networks during deep sleep </span> <cite><abbr title="PNAS" class="site-title">Proc. Natl. Acad. Sci. USA</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">110<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">15419</span><span class="cit-sep">-</span><span class="cit-last-page">15424</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck pnas;110/38/15419 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.pnas.org/cgi/content/abstract/110/38/15419" rel="abstract">Abstract</a></li><li><a href="http://www.pnas.org/cgi/content/full/110/38/15419" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.pnas.org/cgi/reprint/110/38/15419" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior </span> <cite><abbr title="Science Translational Medicine" class="site-title">Sci Transl Med</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">5<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">198ra105</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck scitransmed;5/198/198ra105 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://stm.sciencemag.org/cgi/content/abstract/5/198/198ra105" rel="abstract">Abstract</a></li><li><a href="http://stm.sciencemag.org/cgi/content/full/5/198/198ra105" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://stm.sciencemag.org/cgi/reprint/5/198/198ra105" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Modeling Resting-State Functional Networks When the Cortex Falls Sleep: Local and Global Changes </span> <cite><abbr title="Cerebral Cortex" class="site-title">Cereb Cortex</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">0<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">bht176v1</span><span class="cit-sep">-</span><span class="cit-last-page">bht176</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck cercor;bht176v1 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://cercor.oxfordjournals.org/cgi/content/abstract/bht176v1" rel="abstract">Abstract</a></li><li><a href="http://cercor.oxfordjournals.org/cgi/content/full/bht176v1" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://cercor.oxfordjournals.org/cgi/reprint/bht176v1" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Dissociation of Vegetative and Minimally Conscious Patients Based on Brain Operational Architectonics: Factor of Etiology </span> <cite><abbr title="Clinical EEG and Neuroscience" class="site-title">Clin EEG Neurosci</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">44<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">209</span><span class="cit-sep">-</span><span class="cit-last-page">220</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck speeg;44/3/209 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://eeg.sagepub.com/cgi/content/abstract/44/3/209" rel="abstract">Abstract</a></li><li><a href="http://eeg.sagepub.com/cgi/content/full/44/3/209" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://eeg.sagepub.com/cgi/reprint/44/3/209" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Neural Network-Based Classification of Anesthesia/Awareness Using Granger Causality Features </span> <cite><abbr title="Clinical EEG and Neuroscience" class="site-title">Clin EEG Neurosci</abbr> <span class="cit-print-date">2013 </span><span class="cit-vol">0<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">1550059413486271v1</span><span class="cit-sep">-</span><span class="cit-last-page">1550059413486271</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck speeg;1550059413486271v1 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://eeg.sagepub.com/cgi/content/abstract/1550059413486271v1" rel="abstract">Abstract</a></li><li><a href="http://eeg.sagepub.com/cgi/content/full/1550059413486271v1" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://eeg.sagepub.com/cgi/reprint/1550059413486271v1" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Intrinsic Organization of the Anesthetized Brain </span> <cite><abbr title="Journal of Neuroscience" class="site-title">J. Neurosci.</abbr> <span class="cit-print-date">2012 </span><span class="cit-vol">32<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">10183</span><span class="cit-sep">-</span><span class="cit-last-page">10191</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck jneuro;32/30/10183 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.jneurosci.org/cgi/content/abstract/32/30/10183" rel="abstract">Abstract</a></li><li><a href="http://www.jneurosci.org/cgi/content/full/32/30/10183" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.jneurosci.org/cgi/reprint/32/30/10183" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">The Eternal Silence of Neuronal Spaces </span> <cite><abbr title="Science" class="site-title">Science</abbr> <span class="cit-print-date">2012 </span><span class="cit-vol">336<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">1507</span><span class="cit-sep">-</span><span class="cit-last-page">1508</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck sci;336/6088/1507-a abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.sciencemag.org/cgi/content/summary/336/6088/1507-a" rel="abstract">Abstract</a></li><li><a href="http://www.sciencemag.org/cgi/content/full/336/6088/1507-a" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.sciencemag.org/cgi/reprint/336/6088/1507-a" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Hierarchical clustering of brain activity during human nonrapid eye movement sleep </span> <cite><abbr title="PNAS" class="site-title">Proc. Natl. Acad. Sci. USA</abbr> <span class="cit-print-date">2012 </span><span class="cit-vol">109<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">5856</span><span class="cit-sep">-</span><span class="cit-last-page">5861</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck pnas;109/15/5856 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.pnas.org/cgi/content/abstract/109/15/5856" rel="abstract">Abstract</a></li><li><a href="http://www.pnas.org/cgi/content/full/109/15/5856" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.pnas.org/cgi/reprint/109/15/5856" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Causal density and integrated information as measures of conscious level </span> <cite><abbr title="Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences" class="site-title">Phil Trans R Soc A</abbr> <span class="cit-print-date">2011 </span><span class="cit-vol">369<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">3748</span><span class="cit-sep">-</span><span class="cit-last-page">3767</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck roypta;369/1952/3748 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://rsta.royalsocietypublishing.org/cgi/content/abstract/369/1952/3748" rel="abstract">Abstract</a></li><li><a href="http://rsta.royalsocietypublishing.org/cgi/content/full/369/1952/3748" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://rsta.royalsocietypublishing.org/cgi/reprint/369/1952/3748" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">On the Emergence of Primary Visual Perception </span> <cite><abbr title="Cerebral Cortex" class="site-title">Cereb Cortex</abbr> <span class="cit-print-date">2011 </span><span class="cit-vol">21<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">1941</span><span class="cit-sep">-</span><span class="cit-last-page">1953</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck cercor;21/9/1941 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://cercor.oxfordjournals.org/cgi/content/abstract/21/9/1941" rel="abstract">Abstract</a></li><li><a href="http://cercor.oxfordjournals.org/cgi/content/full/21/9/1941" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://cercor.oxfordjournals.org/cgi/reprint/21/9/1941" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Variability of Brain Signals Processed Locally Transforms into Higher Connectivity with Brain Development </span> <cite><abbr title="Journal of Neuroscience" class="site-title">J. Neurosci.</abbr> <span class="cit-print-date">2011 </span><span class="cit-vol">31<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">6405</span><span class="cit-sep">-</span><span class="cit-last-page">6413</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck jneuro;31/17/6405 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.jneurosci.org/cgi/content/abstract/31/17/6405" rel="abstract">Abstract</a></li><li><a href="http://www.jneurosci.org/cgi/content/full/31/17/6405" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.jneurosci.org/cgi/reprint/31/17/6405" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li><li class="cit"><div class="cit-metadata"><span class="cit-first-element cit-title">Science of the Conscious Mind </span> <cite><abbr title="The Biological Bulletin" class="site-title">Biol. Bull.</abbr> <span class="cit-print-date">2008 </span><span class="cit-vol">215<span class="cit-sep cit-sep-after-article-vol">:</span></span><span class="cit-pages"><span class="cit-first-page">204</span><span class="cit-sep">-</span><span class="cit-last-page">215</span></span></cite>  </div><div class="cit-extra"><span class="accesscheck biolbull;215/3/204 abstract,full,reprint"></span> <ul class="cit-views"><li class="first-item"><a href="http://www.biolbull.org/cgi/content/abstract/215/3/204" rel="abstract">Abstract</a></li><li><a href="http://www.biolbull.org/cgi/content/full/215/3/204" rel="full-text">Full Text</a></li><li class="last-item"><a href="http://www.biolbull.org/cgi/reprint/215/3/204" rel="full-text.pdf">Full Text (PDF)</a></li></ul>  </div> </li></ul></div></div>
         <div style="height: 37233px;" id="col-2">
            
            <div class="article-nav sidebar-nav">
               <a href="http://www.biolbull.org/content/215/3/204.short" title="Previous article" class="previous">« Previous</a><span class="article-nav-sep"> | </span><a href="http://www.biolbull.org/content/215/3/243.short" title="Next article" class="next">Next Article »</a>
               
               <span class="toc-link">
                  				<a href="http://www.biolbull.org/content/215/3.toc" title="Table of Contents">Table of Contents</a>
                  			</span>
               
               
            </div>
            <div class="content-box" id="article-cb-main">
               <div class="cb-contents">
                  <h3 class="cb-contents-header"><span>This Article</span></h3>
                  <div class="cb-section cb-slug">
                     <ol>
                        <li>
                           <div id="slugline">
                              
                              
                              	    
                              
                              <cite>
                                 	    <abbr title="The Biological Bulletin" class="slug-jnl-abbrev">
                                    Biol. Bull.</abbr><span class="slug-pub-date" itemprop="datePublished">
                                    	    December 2008 
                                    </span>
                                 	    <span class="slug-vol">
                                    vol. 215 
                                    </span><span class="slug-issue">
                                    no. 3 
                                    </span><span class="slug-pages">
                                    216-242
                                    </span>
                                 </cite>
                              
                              
                              
                           </div>
                        </li>
                     </ol>
                  </div>
                  <div class="cb-section cb-views">
                     <ol>
                        <li class="abstract-view-link primary"><a href="http://www.biolbull.org/content/215/3/216.abstract" rel="view-abstract">Abstract</a><span class="viewspecificaccesscheck biolbull;215/3/216 abstract free">Free</span></li>
                        <li class="notice full-text-view-link primary"><span class="variant-indicator">» <span>Full Text</span></span><span class="viewspecificaccesscheck biolbull;215/3/216 full free">Free</span></li>
                        <li class="notice full-text-pdf-view-link primary"><a href="http://www.biolbull.org/content/215/3/216.full.pdf+html" rel="view-full-text.pdf">Full Text (PDF)</a><span class="viewspecificaccesscheck biolbull;215/3/216 reprint free">Free</span></li>
                     </ol>
                  </div>
                  <div class="cb-section collapsible" id="cb-art-cat">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">-</span> <span>Classifications</span></a></h4>
                     <ol>
                        <li>
                           <ul class="subject-headings last-child">
                              <li><a class="tocsection-search" href="http://www.biolbull.org/search?tocsectionid=Position+Papers&amp;sortspec=date&amp;submit=Submit">Position Papers</a></li>
                           </ul>
                        </li>
                     </ol>
                  </div>
                  <div class="cb-section collapsible" id="cb-art-svcs">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">-</span> <span>Services</span></a></h4>
                     <ol>
                        <li class="mail-a-friend-link icon-link"><a href="http://www.biolbull.org/email?gca=biolbull;215/3/216&amp;current-view-path=/content/215/3/216.full">
                              Email this article to a colleague</a></li>
                        <li class="alert-link icon-link"><a href="http://www.biolbull.org/cgi/alerts/ctalert?alertType=citedby&amp;addAlert=cited_by&amp;cited_by_criteria_resid=biolbull;215/3/216&amp;saveAlert=no&amp;return-type=article&amp;return_url=http://www.biolbull.org/content/215/3/216.full?view=long&amp;pmid=19098144&amp;related-urls=yes&amp;legid=biolbull;215/3/216">Alert me when this article is cited</a></li>
                        <li class="alert-link icon-link"><a href="http://www.biolbull.org/cgi/alerts/ctalert?alertType=correction&amp;addAlert=correction&amp;correction_criteria_value=215/3/216&amp;saveAlert=no&amp;return-type=article&amp;return_url=http://www.biolbull.org/content/215/3/216.full?view=long&amp;pmid=19098144&amp;related-urls=yes&amp;legid=biolbull;215/3/216">Alert me if a correction is posted</a></li>
                        <li class="similar-link"><a href="http://www.biolbull.org/search?qbe=biolbull;215/3/216&amp;citation=Tononi%20215%20%283%29:%20216&amp;submit=yes">Similar articles in this journal</a></li>
                        <li class="similar-link"><a href="http://www.biolbull.org/external-ref?access_num=19098144&amp;link_type=MED_NBRS" class="similar-link">Similar articles in PubMed</a></li>
                        <li class="cit-man-link icon-link cite-link"><a href="http://www.biolbull.org/citmgr?gca=biolbull;215/3/216">Download to citation manager</a></li>
                     </ol>
                  </div>
                  <div class="cb-section default-closed collapsed" id="cb-art-cit">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">+</span> <span>Citing Articles</span></a></h4>
                     <ol style="display: none;">
                        <li class="hw-citing-link"><a href="#cited-by">View citing article information</a></li>
                     </ol>
                  </div>
                  <div class="cb-section default-closed collapsed" id="cb-art-gs">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">+</span> <span>Google Scholar</span></a></h4>
                     <ol style="display: none;">
                        <li class="cb-art-gs-auth author-link"><a href="http://scholar.google.com/scholar?q=%22author%3ATononi%20author%3AG.%22" class="cb-art-gs-auth author-link">Articles by  Tononi, G.</a></li>
                        <li class="cb-art-gs-rel similar-link"><a href="http://www.biolbull.org/external-ref?access_num=http://www.biolbull.org/content/215/3/216.abstract&amp;link_type=GOOGLESCHOLARRELATED">Search for related content</a></li>
                     </ol>
                  </div>
                  <div class="cb-section default-closed collapsed" id="cb-art-pm">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">+</span> <span>PubMed</span></a></h4>
                     <ol style="display: none;">
                        <li class="cb-art-pm-cite cite-link icon-link"><a href="http://www.biolbull.org/external-ref?access_num=19098144&amp;link_type=PUBMED" class="cb-art-pm-cite cite-link icon-link">PubMed citation</a></li>
                        <li class="cb-art-pm-auth author-link"><a href="http://www.biolbull.org/external-ref?access_num=Tononi%20G&amp;link_type=AUTHORSEARCH" class="cb-art-pm-auth author-link">Articles by  Tononi, G.</a></li>
                        <li class="nodata">
                           <div id="cb-entrez-links-none">No NCBI links</div>
                        </li>
                     </ol>
                  </div>
                  <div class="cb-section default-closed collapsed" id="cb-art-rel">
                     <h4 class="cb-section-header"><a href="#" class="collapse-toggle"><span class="view-more">+</span> <span>Related Content</span></a></h4>
                     <ol style="display: none;">
                        <li><a href="#related-urls">Related Web Pages</a></li>
                     </ol>
                  </div>
               </div>
            </div>
            
            
            <div class="content-box" id="article-dyn-nav">
               <div class="cb-contents">
                  <h3 class="cb-contents-header"><span>Navigate This Article</span></h3>
                  <div class="cb-section" id="cb-art-nav">
                     <ol>
                        <li><a href="#content-block">Top</a></li>
                        <li><a href="#abstract-1">Abstract</a></li>
                        <li><a href="#sec-1">INTRODUCTION</a></li>
                        <li><a href="#sec-2">A Phenomenological Analysis: Consciousness as Integrated Information</a></li>
                        <li><a href="#sec-5">A Mathematical Analysis: Quantifying Integrated Information</a></li>
                        <li><a href="#sec-9">A Neurobiological Reality Check: Accounting for Empirical Observations</a></li>
                        <li><a href="#sec-10">The Quality of Consciousness: Characterizing Informational Relationships</a></li>
                        <li><a href="#sec-14">A Provisional Manifesto</a></li>
                        <li><a href="#ack-1">Acknowledgments</a></li>
                        <li><a href="#fn-group-1">Footnotes</a></li>
                        <li><a href="#ref-list-1">Notes</a></li>
                        <li><a href="#ref-list-2">Literature Cited</a></li>
                     </ol>
                  </div>
               </div>
            </div>
            
         <div style="display: block;" id="docked-nav" class="dockblock"><div class="content-box" id="docked-cb"><div class="cb-contents"><h3>This Article</h3><div class="cb-section cb-slug"><ol id="docked-slug"><li><div id="slugline">
                              
                              
                              	    
                              
                              <cite>
                                 	    <abbr title="The Biological Bulletin" class="slug-jnl-abbrev">
                                    Biol. Bull.</abbr><span class="slug-pub-date" itemprop="datePublished">
                                    	    December 2008 
                                    </span>
                                 	    <span class="slug-vol">
                                    vol. 215 
                                    </span><span class="slug-issue">
                                    no. 3 
                                    </span><span class="slug-pages">
                                    216-242
                                    </span>
                                 </cite>
                              
                              
                              
                           </div></li></ol></div><div class="cb-section"><ol id="docked-nav-views"><li class="abstract-view-link primary"><a href="http://www.biolbull.org/content/215/3/216.abstract" rel="view-abstract">Abstract</a><span class="viewspecificaccesscheck biolbull;215/3/216 abstract free">Free</span></li><li class="notice full-text-view-link primary"><span class="variant-indicator">» <span>Full Text</span></span><span class="viewspecificaccesscheck biolbull;215/3/216 full free">Free</span></li><li class="notice full-text-pdf-view-link primary"><a href="http://www.biolbull.org/content/215/3/216.full.pdf+html" rel="view-full-text.pdf">Full Text (PDF)</a><span class="viewspecificaccesscheck biolbull;215/3/216 reprint free">Free</span></li></ol></div></div></div><div class="content-box" id="article-dyn-nav">
               <div class="cb-contents">
                  <h3 class="cb-contents-header"><span>Navigate This Article</span></h3>
                  <div class="cb-section" id="cb-art-nav">
                     <ol>
                        <li><a href="#content-block">Top</a></li>
                        <li><a href="#abstract-1">Abstract</a></li>
                        <li><a href="#sec-1">INTRODUCTION</a></li>
                        <li><a href="#sec-2">A Phenomenological Analysis: Consciousness as Integrated Information</a></li>
                        <li><a href="#sec-5">A Mathematical Analysis: Quantifying Integrated Information</a></li>
                        <li><a href="#sec-9">A Neurobiological Reality Check: Accounting for Empirical Observations</a></li>
                        <li><a href="#sec-10">The Quality of Consciousness: Characterizing Informational Relationships</a></li>
                        <li><a href="#sec-14">A Provisional Manifesto</a></li>
                        <li><a href="#ack-1">Acknowledgments</a></li>
                        <li><a href="#fn-group-1">Footnotes</a></li>
                        <li><a href="#ref-list-1">Notes</a></li>
                        <li><a href="#ref-list-2">Literature Cited</a></li>
                     </ol>
                  </div>
               </div>
            </div></div></div>
         <div style="height: 37233px;" id="col-3">
            
            <div class="content-box" id="sidebar-current-issue">
               <div class="cb-contents">
                  <h3 class="cb-contents-header"><span>This Month's Issue</span></h3>
                  <div class="cb-section">
                     <ol>
                        <li><span><a href="http://www.biolbull.org/content/current" rel="current-issue">October 2013, 225 (2)</a></span></li>
                     </ol>
                  </div>
                  <div class="cb-section">
                     <ol>
                        <li>
                           <div class="current-issue"><a href="http://www.biolbull.org/content/current" rel="current-issue"><img src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/2.gif" alt="Current Issue" height="89" width="67"></a></div>
                        </li>
                     </ol>
                  </div>
                  <div class="cb-section sidebar-etoc-link">
                     <ol>
                        <li><a href="http://www.biolbull.org/cgi/alerts/etoc">Alert me to new issues of Biol. Bull.
                              </a></li>
                     </ol>
                  </div>
               </div>
            </div>
            <div id="sidebar-global-nav">
               
               <ul class="button-list pub-links">
                  <li class="first"><a href="http://www.biolbull.org/site/misc/ifora.xhtml" title="INSTRUCTIONS TO AUTHORS"><span>INSTRUCTIONS TO AUTHORS</span></a></li>
                  <li><a href="http://www.biolbull.org/site/misc/about.xhtml" title="ABOUT THE JOURNAL"><span>ABOUT THE JOURNAL</span></a></li>
                  <li><a href="http://www.biolbull.org/site/misc/edboard.xhtml" title="EDITORIAL BOARD"><span>EDITORIAL BOARD</span></a></li>
                  <li><a href="http://www.biolbull.org/subscriptions/" title="SUBSCRIBER HELP"><span>SUBSCRIBER HELP</span></a></li>
                  <li><a href="http://www.biolbull.org/site/misc/addir.xhtml" title="INFORMATION FOR ADVERTISERS"><span>INFORMATION FOR ADVERTISERS</span></a></li>
                  <li><a href="http://www.biolbull.org/site/misc/permissions.xhtml" title="PERMISSIONS"><span>PERMISSIONS</span></a></li>
                  <li><a href="http://www.biolbull.org/cgi/collection" title="SUBJECT COLLECTIONS"><span>SUBJECT COLLECTIONS</span></a></li>
                  <li><a href="http://www.biolbull.org/site/subscriptions/sample.xhtml" title="FREE SAMPLE ISSUE"><span>FREE SAMPLE ISSUE</span></a></li>
                  <li><a href="http://www.biolbull.org/site/subscriptions/etoc.xhtml" title="EMAIL ALERTS"><span>EMAIL ALERTS</span></a></li>
                  <li><a target="_blank" href="http://www.facebook.com/thebiologicalbulletin" rel="external-nw" title="FACEBOOK [opens in a new window]"><span>FACEBOOK</span></a></li>
                  <li><a href="http://www.biolbull.org/rss" title="RSS FEEDS"><span>RSS FEEDS</span>
                        
                        <img alt="RSS Feeds" src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/rss.gif"></a>
                     		
                     		
                     	
                  </li>
                  <li class="last"><a href="http://www.biolbull.org/feedback" title="FEEDBACK"><span>FEEDBACK</span></a></li>
               </ul>
               
               <div class="sidebar-icon-group">
                  <a title="[opens in a new window]" target="_blank" href="http://www.mbl.edu/" rel="external-nw"><img src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/society_logo.gif" class="publisher-icon" alt="Society Logo"></a>
                  <a title="[opens in a new window]" target="_blank" href="http://highwire.stanford.edu/" rel="external-nw"><img src="Consciousness%20as%20Integrated%20Information:%20a%20Provisional%20Manifesto_files/hplogo.gif" class="hw-icon" alt="HighWire Press Logo"></a>
                  
               </div>
               
            </div>
            <div class="most-links-box ">
               
               <div class="most-header">
                  
                  <h3>Most</h3><ul class="most-headings"><li class="most-cur-sel"><a href="#">Viewed</a></li><li><a href="#">Cited</a></li></ul>
                  
               </div>
               
               <ul>
                  <li class="most-cur-sel">
                     <h4>Viewed</h4>
                     
                     
                     <div class="most-list">
                        
                        <ol>
                           <li class="first-item"><a href="http://www.biolbull.org/cgi/content/short/215/3/216?rss=1&amp;amp;ssource=mfr">Consciousness as Integrated Information: a Provisional Manifesto</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/190/3/302?rss=1&amp;amp;ssource=mfr">Reversing the Life Cycle: Medusae Transforming into Polyps and Cell Transdifferentiation in Turritopsis nutricula (Cnidaria,
                                 Hydrozoa)</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/210/3/308?rss=1&amp;amp;ssource=mfr">The Octopus: A Model for a Comparative Analysis of the Evolution of Learning and Memory Mechanisms</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/218/1/15?rss=1&amp;amp;ssource=mfr">A "Mimic Octopus" in the Atlantic: Flatfish Mimicry and Camouflage by Macrotritopus defilippi</a></li>
                           <li class="last-item"><a href="http://www.biolbull.org/cgi/content/short/211/2/106?rss=1&amp;amp;ssource=mfr">Mammalian and Avian Neuroanatomy and the Question of Consciousness in Birds</a></li>
                        </ol>
                        <a href="http://www.biolbull.org/reports/mfr1.dtl" class="view-all">» View all Most Viewed articles</a>
                        
                     </div>
                     
                     
                  </li>
                  <li>
                     <h4>Cited</h4>
                     
                     
                     <div class="most-list">
                        
                        <ol>
                           <li class="first-item"><a href="http://www.biolbull.org/cgi/content/short/198/2/203?rss=1&amp;amp;ssource=mfc">Mechanisms of animal navigation in odor plumes</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/115/3/440?rss=1&amp;amp;ssource=mfc">A PERSISTENT DIURNAL RHYTHM OF LUMINESCENCE IN GONYAULAX POLYEDRA</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/198/2/188?rss=1&amp;amp;ssource=mfc">The fluid dynamical context of chemosensory behavior</a></li>
                           <li><a href="http://www.biolbull.org/cgi/content/short/191/1/129?rss=1&amp;amp;ssource=mfc">Eddy Chemotaxis and Odor Landscapes: Exploration of Nature With Animal Sensors</a></li>
                           <li class="last-item"><a href="http://www.biolbull.org/cgi/content/short/183/2/304?rss=1&amp;amp;ssource=mfc">Morphology of the Brain of Crayfish, Crabs, and Spiny Lobsters: A Common Nomenclature for Homologous Structures</a></li>
                        </ol>
                        <a href="http://www.biolbull.org/reports/mfc1.dtl" class="view-all">» View all Most Cited articles</a>
                        
                     </div>
                     
                     
                  </li>
               </ul>
               
               
            </div>
            
            
            
         </div>
         <div id="footer">
            
            <div class="bar">
               
               <div class="footer-group footer-col-left">
                  	    
                  <p class="copyright"><a href="http://www.biolbull.org/site/misc/terms.xhtml" id="cp-url">Copyright © 2013 by the Marine Biological Laboratory</a></p>
                  	    
                  	  
               </div>
               
               <div class="footer-group footer-col-right">
                  	    
                  <ul class="issns">
                     <li>
                        <span>Print ISSN: </span>
                        <span class="issn">0006-3185</span>
                        
                     </li>
                     <li>
                        <span>Online ISSN: </span>
                        <span class="issn">1939-8697</span>
                        
                     </li>
                  </ul>
                  	  
               </div>
               	  
            </div>
            
            
            <div class="block-2 sb-div"></div>
            
         </div>
      </div>
   
<div id="fancybox-tmp"></div><div id="fancybox-loading"><div></div></div><div id="fancybox-overlay"></div><div id="fancybox-wrap"><div id="fancybox-outer"><div class="fancybox-bg" id="fancybox-bg-n"></div><div class="fancybox-bg" id="fancybox-bg-ne"></div><div class="fancybox-bg" id="fancybox-bg-e"></div><div class="fancybox-bg" id="fancybox-bg-se"></div><div class="fancybox-bg" id="fancybox-bg-s"></div><div class="fancybox-bg" id="fancybox-bg-sw"></div><div class="fancybox-bg" id="fancybox-bg-w"></div><div class="fancybox-bg" id="fancybox-bg-nw"></div><div id="fancybox-content"></div><a id="fancybox-close"></a><div id="fancybox-title"></div><a href="javascript:;" id="fancybox-left"><span class="fancy-ico" id="fancybox-left-ico"></span></a><a href="javascript:;" id="fancybox-right"><span class="fancy-ico" id="fancybox-right-ico"></span></a></div></div></body></html>